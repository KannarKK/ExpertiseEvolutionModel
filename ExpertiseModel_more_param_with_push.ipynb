{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: import simplejson as json\n",
    "except ImportError: import json\n",
    "\n",
    "import gzip,codecs,numpy as np,random,copy\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704815 4760 2709575\n"
     ]
    }
   ],
   "source": [
    "with open(\"ratebeer_train_random.json\",\"r\") as infile:\n",
    "    train = json.load(infile)\n",
    "infile.close()\n",
    "with open(\"ratebeer_test_random.json\",\"r\") as infile:\n",
    "    test = json.load(infile)\n",
    "infile.close()\n",
    "with open(\"ratebeer_quickmap_random.json\",\"r\") as infile:\n",
    "    quickmap = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "print(len(train),len(test),len(quickmap))\n",
    "train = sorted(train, key = lambda k : k[\"review/time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iu = dict() #set of products reviewed by users\n",
    "Ui = dict() #set of users who reviewed the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in train:\n",
    "        item = review[\"product/productId\"]\n",
    "        user = review[\"review/userId\"]\n",
    "        if item in Ui:\n",
    "            Ui[item].append(user)\n",
    "        else:\n",
    "            Ui[item] = [user]\n",
    "        if user in Iu:\n",
    "            Iu[user].append(item)\n",
    "        else:\n",
    "            Iu[user] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760\n"
     ]
    }
   ],
   "source": [
    "print(len(Iu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760 110032\n"
     ]
    }
   ],
   "source": [
    "distinct_user_set = set()\n",
    "distinct_item_set = set()\n",
    "for review in train:\n",
    "    if review[\"review/userId\"] not in distinct_user_set:\n",
    "        distinct_user_set.add(review[\"review/userId\"])\n",
    "    if review[\"product/productId\"] not in distinct_item_set:\n",
    "        distinct_item_set.add(review[\"product/productId\"])\n",
    "print(len(distinct_user_set), len(distinct_item_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expertise modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExpertiseLFM(object):\n",
    "    ''' Expertise LFM class implements the evolution latent factor model of collaborative filtering \n",
    "    using matrix factorization\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,train_data, Iu_reg, Ui_reg, userproduct_dict,userset,itemset,k,Lambda1,Lambda2,E):\n",
    "        ''' requires Iu and Ui matrix information, quick mapping of reviews to (user,product),\n",
    "         k =number of latent factor dimensions, \n",
    "         lambda1 = reg parameter, lambda2 = smoothing parameter,\n",
    "         E = number of experience levels.\n",
    "        '''\n",
    "        \n",
    "        self.Ntrain = len(train_data)               #Number of training samples\n",
    "        self.train_data = train_data                #training data \n",
    "        self.Iu = self.deepish_copy(Iu_reg)         #Iu mapping  \n",
    "        self.Ui = self.deepish_copy(Ui_reg)         #Ui mapping\n",
    "        self.quickmap = userproduct_dict            #uses key as (userid-itemid) for quick mapping to required review\n",
    "        self.user_set = userset\n",
    "        self.item_set = itemset\n",
    "        \n",
    "        self.user_map = {}     #mapping for easier transformation from long gradient vector to individual gradients\n",
    "        self.item_map = {}\n",
    "        self.reverse_user_map = {}\n",
    "        self.reverse_item_map = {}\n",
    "        i=0\n",
    "        for user in self.user_set:\n",
    "            self.user_map[i] = user\n",
    "            self.reverse_user_map[user] = i\n",
    "            i+=1\n",
    "        i=0\n",
    "        for item in self.item_set:\n",
    "            self.item_map[i] = item\n",
    "            self.reverse_item_map[user] = i\n",
    "            i+=1\n",
    "        \n",
    "        #hyperparameters\n",
    "        self.Lambda1 = Lambda1    #regularization param\n",
    "        self.Lambda2 = Lambda2    #smoothing reg param     \n",
    "        self.k = k                # number of latent factor dimension (low dimensional repr)\n",
    "        self.E = E                #number of experience levels\n",
    "        \n",
    "        self.final_param = self.init_theta()  #current final_parameters\n",
    "        self.init_exp()\n",
    "    \n",
    "    \n",
    "    def init_theta(self):\n",
    "        ''' Initializes the parameters of E recommender models\n",
    "        \n",
    "        flat_theta = <alpha_G, Bu_G, Bi_G, alpha_e1..E, Bu_e1..E, Bi_e1..E, Gu_e1...E, Gi_e1...E>\n",
    "        '''\n",
    "        flat_theta = []\n",
    "        \n",
    "        rating_arr = [review[\"review/score\"] for review in self.train_data]\n",
    "        avg_rating = np.mean(rating_arr)\n",
    "        self.alpha_G = avg_rating                                 #global offset\n",
    "        self.Bu_G = dict()                                        #user bias (global)\n",
    "        self.Bi_G = dict()                                        #item bias (global)\n",
    "        \n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu_G[self.user_map[i]] = np.random.random(1).item() \n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi_G[self.item_map[i]] = np.random.random(1).item() \n",
    "        \n",
    "        flat_theta.append(self.alpha_G)\n",
    "        flat_theta.extend(list(self.Bu_G.values()))\n",
    "        flat_theta.extend(list(self.Bi_G.values()))\n",
    "        \n",
    "        self.alpha = np.random.rand(self.E)                     #individual offset parameters per exp\n",
    "        self.Bu = [dict() for i in range(self.E)]               #user bias per exp\n",
    "        self.Bi = [dict() for i in range(self.E)]               #item bias per exp\n",
    "        self.Gu = [dict() for i in range(self.E)]               #user latent factor vector repr per exp\n",
    "        self.Gi = [dict() for i in range(self.E)]               #item latent factor vector repr per exp\n",
    "        \n",
    "        flat_theta.extend(self.alpha)\n",
    "        for e in range(self.E):\n",
    "            for i in range(len(self.user_map)):\n",
    "                self.Bu[e][self.user_map[i]] = np.random.random(1).item()\n",
    "                flat_theta.append(self.Bu[e][self.user_map[i]]) \n",
    "        for e in range(self.E):        \n",
    "            for j in range(len(self.item_map)):\n",
    "                self.Bi[e][self.item_map[j]] = np.random.random(1).item() \n",
    "                flat_theta.append(self.Bi[e][self.item_map[j]])\n",
    "        for e in range(self.E):\n",
    "            for i in range(len(self.user_map)):\n",
    "                self.Gu[e][self.user_map[i]] = np.random.uniform(0,1,(1,self.k))\n",
    "                flat_theta.extend(np.array(list(self.Gu[e][self.user_map[i]])).flatten())\n",
    "        for e in range(self.E):        \n",
    "            for j in range(len(self.item_map)):\n",
    "                self.Gi[e][self.item_map[j]] = np.random.uniform(0,1,(1,self.k))\n",
    "                flat_theta.extend(np.array(list(self.Gi[e][self.item_map[j]])).flatten())\n",
    "        \n",
    "        self.recparam = (1 + len(self.user_set) + len(self.item_set) \\\n",
    "                            + self.k*(len(self.user_set) + len(self.item_set))) #per experience level parameters\n",
    "        self.globalparam = 1 + len(self.user_set) + len(self.item_set)   #global parameters\n",
    "        self.totalparams = self.recparam * self.E + self.globalparam\n",
    "        \n",
    "        return np.array(flat_theta)\n",
    "    \n",
    "    def init_exp(self):\n",
    "        ''' Initializes experience for each user-item combination uniformly over rating time'''\n",
    "        self.eui = dict()  #experience dictionary of dictionaries (1: user level, 2: item level)\n",
    "        for user in self.user_set:\n",
    "            self.eui[user] = {}\n",
    "            num_items_in_level = round(len(self.Iu[user])/self.E)\n",
    "            if num_items_in_level ==0:\n",
    "                print(len(self.Iu[user]),user)\n",
    "            cur_level = 0\n",
    "            item = self.Iu[user][0]\n",
    "            self.eui[user][item] = cur_level\n",
    "            for i in range(1,len(self.Iu[user])):\n",
    "                if i% num_items_in_level == 0 and cur_level != self.E-1 :\n",
    "                     cur_level+=1\n",
    "                item = self.Iu[user][i]\n",
    "                self.eui[user][item] = cur_level\n",
    "                \n",
    "    def OPT_rec(self,i,j,n,user):\n",
    "        '''\n",
    "         i = current experience level, j = jth rating of user, n = number of ratings given by user\n",
    "         internally modelled as experience 0 to E-1 (so experience E is invalid)\n",
    "        '''\n",
    "        if i==self.E or j==n:\n",
    "            return np.inf\n",
    "        elif self.OPT[i,j] >=0: #intial value = -1\n",
    "            return self.OPT[i,j]\n",
    "        else:\n",
    "            item = self.Iu[user][j]  # jth rating\n",
    "            rating = self.quickmap[user+\"-\"+item][\"review/score\"]\n",
    "            temp  = min(self.OPT_rec(i+1,j+1,n,user), self.OPT_rec(i,j+1,n,user))\n",
    "            rec_e = self.alpha_G + self.Bu_G[user] + self.Bi_G[item] + \\\n",
    "                    self.alpha[i] + self.Bu[i][user] + self.Bi[i][item] + \\\n",
    "                    np.asscalar(np.dot(self.Gu[i][user], self.Gi[i][item].T))\n",
    "            if temp == np.inf:\n",
    "                self.OPT[i,j] = (rec_e - rating)**2 \n",
    "            else:\n",
    "                self.OPT[i,j] = (rec_e - rating)**2 + temp\n",
    "                  \n",
    "            return self.OPT[i,j]\n",
    "        \n",
    "    def assign_exp_level(self):\n",
    "        ''' Using the DP solution similar to Longest Common SubSequence, predict new experience level\n",
    "        for each user-item combination'''\n",
    "        k = 0\n",
    "        count=0\n",
    "        for user in self.Iu:\n",
    "            n = len(self.Iu[user])\n",
    "            self.OPT = np.matrix([[-1.0]*n]*self.E)  #initialize to invalid values\n",
    "            for i in range(self.E):\n",
    "                self.OPT_rec(i,0,n,user)\n",
    "            cur_level = np.argmin(self.OPT[:,0])\n",
    "            j = 0\n",
    "            item = self.Iu[user][j]\n",
    "            self.eui[user][item] = cur_level\n",
    "            start_level = cur_level\n",
    "            j+=1\n",
    "            while (j < n):\n",
    "                try: \n",
    "                    if cur_level != self.E-1 and self.OPT[cur_level,j] >= self.OPT[cur_level+1,j]:\n",
    "                        cur_level +=1\n",
    "                    item = self.Iu[user][j]\n",
    "                    if cur_level != self.eui[user][item]:\n",
    "                        count+=1\n",
    "                    self.eui[user][item] = cur_level\n",
    "                    j+=1\n",
    "                except Exception as e:\n",
    "                    print(e.args,i,j,n)\n",
    "            if k%1000==0:\n",
    "                print(\"user: {} start level: {} end level: {}\".format(user,start_level,cur_level))\n",
    "            k+=1 \n",
    "        print(\"Number of experience levels changed:{}\".format(count))\n",
    "        return count\n",
    "\n",
    "    def retrieve_theta_components(self,theta):\n",
    "        ''' Sets all parameters from the long theta vector obtained after update rule'''\n",
    "        j = 0\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        self.alpha_G = theta[j]\n",
    "        j+=1\n",
    "        for i in range(umap_len):\n",
    "            self.Bu_G[self.user_map[i]] = theta[j]\n",
    "            j+=1\n",
    "        for i in range(imap_len):\n",
    "            self.Bi_G[self.item_map[i]] = theta[j]\n",
    "            j+=1 \n",
    "        for e in range(self.E):\n",
    "            self.alpha[e] = theta[j]\n",
    "            j+=1   \n",
    "        for e in range(self.E):\n",
    "            for i in range(umap_len):\n",
    "                self.Bu[e][self.user_map[i]] = theta[j]\n",
    "                j+=1\n",
    "        for e in range(self.E):\n",
    "            for i in range(imap_len):\n",
    "                self.Bi[e][self.item_map[i]] = theta[j]\n",
    "                j+=1 \n",
    "        for e in range(self.E):\n",
    "            for i in range(umap_len):\n",
    "                self.Gu[e][self.user_map[i]] = np.array(theta[j:j+self.k])\n",
    "                j+=self.k  \n",
    "        for e in range(self.E):\n",
    "            for i in range(imap_len):\n",
    "                self.Gi[e][self.item_map[i]] = np.array(theta[j:j+self.k])\n",
    "                j+=self.k                    \n",
    "    \n",
    "    def pred_e(self,user,item,e):\n",
    "        return self.alpha_G + self.Bu_G[user] + self.Bi_G[item] +\\\n",
    "                      self.alpha[e] + self.Bu[e][user] + self.Bi[e][item] +\\\n",
    "                      np.asscalar(np.dot(self.Gu[e][user], self.Gi[e][item].T))\n",
    "    \n",
    "    def f(self,theta):\n",
    "        '''Calculates the value of the objective function (loss) on the training data. '''\n",
    "        self.retrieve_theta_components(theta)\n",
    "        #mean squared error\n",
    "        error = 0\n",
    "        for review in self.train_data:\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            error += (self.pred_e(user,item,e) - review[\"review/score\"])**2\n",
    "        error /= self.Ntrain\n",
    "        #regularization terms\n",
    "        reg_complexity = 0\n",
    "        #ignore global values for now in regularization\n",
    "        #Bu_np = np.array(list(self.Bu_G.values()))\n",
    "        #Bi_np = np.array(list(self.Bi_G.values()))\n",
    "        #reg_complexity = np.sum(np.square(Bu_np)) + np.sum(np.square(Bi_np))\n",
    "        for e in range(self.E):\n",
    "            reg_complexity += np.square(self.alpha[e])\n",
    "            Bu_np = np.array(list(self.Bu[e].values()))\n",
    "            Bi_np = np.array(list(self.Bi[e].values()))\n",
    "            reg_complexity += np.sum(np.square(Bu_np)) + np.sum(np.square(Bi_np))\n",
    "            for user in self.Gu[e]:\n",
    "                reg_complexity += np.linalg.norm(self.Gu[e][user])**2\n",
    "            for item in self.Gi[e]:\n",
    "                reg_complexity += np.linalg.norm(self.Gi[e][item])**2\n",
    "        #regularization (smoothing cost)\n",
    "        reg_term = 0\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        for e in range(1,self.E):\n",
    "            reg_term += (self.alpha[e-1] - self.alpha[e])**2\n",
    "        for e in range(1,self.E):\n",
    "            for i in range(umap_len):\n",
    "                reg_term += (self.Bu[e-1][self.user_map[i]] - self.Bu[e][self.user_map[i]])**2\n",
    "        for e in range(self.E):\n",
    "            for i in range(imap_len):\n",
    "                reg_term += (self.Bi[e-1][self.item_map[i]] - self.Bi[e][self.item_map[i]])**2       \n",
    "        for e in range(self.E):\n",
    "            for i in range(umap_len):\n",
    "                reg_term += np.linalg.norm(self.Gu[e-1][self.user_map[i]] - self.Gu[e][self.user_map[i]])**2  \n",
    "        for e in range(self.E):\n",
    "            for i in range(imap_len):\n",
    "                reg_term += np.linalg.norm(self.Gi[e-1][self.item_map[i]] - self.Gi[e][self.item_map[i]])**2\n",
    "        return (error + self.Lambda1* reg_complexity +  self.Lambda2 * reg_term)*0.5\n",
    "    \n",
    "    def fprime(self, theta):\n",
    "        ''' Calculates the gradient of objective function f()'''\n",
    "        self.retrieve_theta_components(theta)\n",
    "        flat_gradient = []\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        #compute gradient wrt global parameters\n",
    "        flat_gradient.append(self.compute_gradient_wrt_alpha_global())\n",
    "        Bu_grad = self.compute_gradient_wrt_Bu_global()\n",
    "        Bi_grad = self.compute_gradient_wrt_Bi_global()\n",
    "        flat_gradient.extend(list(Bu_grad.values()))\n",
    "        flat_gradient.extend(list(Bi_grad.values()))\n",
    "        #compute gradient wrt experience parameters\n",
    "        for e in range(self.E):\n",
    "            flat_gradient.append(self.compute_gradient_wrt_alpha(e))\n",
    "        for e in range(self.E): \n",
    "            Bu_grad = self.compute_gradient_wrt_Bu(e)\n",
    "            flat_gradient.extend(list(Bu_grad.values()))\n",
    "        for e in range(self.E):\n",
    "            Bi_grad = self.compute_gradient_wrt_Bi(e)\n",
    "            flat_gradient.extend(list(Bi_grad.values()))\n",
    "        for e in range(self.E):\n",
    "            Gu_grad = self.compute_gradient_wrt_Gu(e)\n",
    "            flat_gradient.extend(np.array(list(Gu_grad.values())).flatten())\n",
    "        for e in range(self.E):\n",
    "            Gi_grad = self.compute_gradient_wrt_Gi(e)\n",
    "            flat_gradient.extend(np.array(list(Gi_grad.values())).flatten())\n",
    "        return np.array(flat_gradient)\n",
    "    \n",
    "    def vanilla_gd(self,eta,guess):\n",
    "        self.i =0;\n",
    "        flat_theta_guess = guess\n",
    "        for i in range(100):\n",
    "            flat_gradient = self.fprime(flat_theta_guess)\n",
    "            flat_theta_guess -= eta*flat_gradient\n",
    "            if i%50 ==0: print(\"{} U : Objective value: {}\".format(i,self.f(flat_theta_guess)))\n",
    "            self.i +=1\n",
    "        return flat_theta_guess\n",
    "    \n",
    "    def vanilla_als (self,eta):\n",
    "        guess = self.init_theta()\n",
    "        #print(\"param = \",guess[self.recparam])\n",
    "        for m in range(100):\n",
    "            guess = self.vanilla_gd(eta, guess)\n",
    "            self.final_param = guess\n",
    "            self.retrieve_theta_components(guess)\n",
    "            count = self.assign_exp_level()\n",
    "            if count==0:\n",
    "                print(\"Breaking\")\n",
    "                return\n",
    "\n",
    "    def call(self,theta):\n",
    "        print(\"{} Objective value: {}\".format(self.i, self.f(theta)))\n",
    "        self.i+=1\n",
    "    \n",
    "    def objectiveloss_lbfgs(self,thetaguess, grad_tolerance):\n",
    "        self.i =0;\n",
    "        flat_theta_guess = thetaguess\n",
    "        flat_theta,value,d = opt.fmin_l_bfgs_b(self.f,flat_theta_guess,self.fprime,\\\n",
    "                                              pgtol = grad_tolerance,disp=True,\\\n",
    "                                              maxiter = 10, callback = self.call, iprint=0)\n",
    "        #set the final parameters to the final value returned by fmin_l_bfgs_b\n",
    "        return flat_theta\n",
    "    \n",
    "    \n",
    "    def push_model(self):\n",
    "        ''' push the model towards more regularized place'''\n",
    "        e_alpha_avg = np.mean(self.alpha)\n",
    "        self.alpha_G += e_alpha_avg\n",
    "        self.alpha -= e_alpha_avg\n",
    "        \n",
    "        for user in self.Bu_G:\n",
    "            e_Bu_avg = 0 \n",
    "            for e in range(self.E):\n",
    "                e_Bu_avg += self.Bu[e][user]\n",
    "            e_Bu_avg /= self.E\n",
    "            self.Bu_G[user] += e_Bu_avg\n",
    "            for e in range(self.E):\n",
    "                self.Bu[e][user] -= e_Bu_avg\n",
    "        for item in self.Bi_G:\n",
    "            e_Bi_avg = 0\n",
    "            for e in range(self.E):\n",
    "                e_Bi_avg += self.Bi[e][item]\n",
    "            e_Bi_avg /= self.E\n",
    "            self.Bi_G[item] += e_Bi_avg\n",
    "            for e in range(self.E):\n",
    "                self.Bi[e][item] -= e_Bi_avg\n",
    "    \n",
    "    def als (self,grad_tolerance):\n",
    "        ''' bad name. not exactly ALS, but performs LBFGS gradient descent, and sets experience level'''\n",
    "        guess = self.final_param\n",
    "        for m in range(10):\n",
    "            print(\"Iteration {}:\".format(m+1))\n",
    "            print(\"Objective function value: {}\".format(self.f(guess)))\n",
    "            guess = self.objectiveloss_lbfgs(guess, grad_tolerance)\n",
    "            self.final_param = guess.copy()\n",
    "            self.retrieve_theta_components(guess)\n",
    "            self.push_model()\n",
    "            print(\"Model alpha parameters: \",[a + self.alpha_G for a in self.alpha])\n",
    "            count = self.assign_exp_level()\n",
    "            print(\"Objective function value: {}\".format(self.f(guess)))\n",
    "            if count==0:\n",
    "                print(\"Breaking\")\n",
    "                return\n",
    "            \n",
    "\n",
    "    def mse_test(self,test_data):\n",
    "        ''' Uses Mean Squared Error as evaluation metric on test data provided by user'''\n",
    "        self.retrieve_theta_components(self.final_param)\n",
    "        error = 0\n",
    "        unknown_data_count =0;\n",
    "        for review in test_data:\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            #assign nearest experience to user-item combo\n",
    "            rtime = review[\"review/time\"]\n",
    "            time_arr = []\n",
    "            for it in self.Iu[user]:\n",
    "                time_arr.append(self.quickmap[user+\"-\"+it][\"review/time\"])\n",
    "            \n",
    "            if all(time_arr[i] <= time_arr[i+1] for i in range(len(time_arr)-1))==\"False\":\n",
    "                print(\"raising error. Something went wrong. List should be sorted by default\")\n",
    "            index = np.searchsorted(time_arr,rtime)\n",
    "            if index == len(self.Iu[user]):\n",
    "                closest_it = self.Iu[user][index-1]\n",
    "            else:\n",
    "                closest_it = self.Iu[user][index]\n",
    "            \n",
    "            e = self.eui[user][closest_it]\n",
    "            \n",
    "            try:\n",
    "                error += (self.pred_e(user,item,e) - review[\"review/score\"])**2\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                unknown_data_count+=1\n",
    "        \n",
    "        if unknown_data_count>0:\n",
    "            print(\"Warning! Unknown {} new data rows; Incorporating this into MSE\".format(unknown_data_count))\n",
    "        return error / (len(test_data) - unknown_data_count)\n",
    "    \n",
    "    def compute_gradient_wrt_alpha_global(self):\n",
    "        tempsum = 0\n",
    "        for review in self.train_data:  #each user item id combo\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            tempsum += ( self.pred_e(user,item,e) - review[\"review/score\"])\n",
    "        tempsum /= self.Ntrain\n",
    "        return tempsum\n",
    "        \n",
    "    def compute_gradient_wrt_Bu_global(self):\n",
    "        Bu_grad = {}\n",
    "        for user in self.Bu_G: \n",
    "            total = 0.0\n",
    "            for item in self.Iu[user]:\n",
    "                e = self.eui[user][item]\n",
    "                total += (self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            #total += self.Lambda1*self.Bu_G[user]\n",
    "            Bu_grad[user] = total\n",
    "        return Bu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Bi_global(self):\n",
    "        Bi_grad = {}\n",
    "        for item in self.Bi_G:\n",
    "            total = 0.0\n",
    "            for user in self.Ui[item]:\n",
    "                e = self.eui[user][item]\n",
    "                total += (self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            #total += self.Lambda1*self.Bi_G[item]\n",
    "            Bi_grad[item] = total\n",
    "        return Bi_grad\n",
    "    \n",
    "    def compute_gradient_wrt_alpha(self,exp):\n",
    "        ''' Compute gradient of objective with respect to alpha parameter of given experience exp level'''\n",
    "        tempsum = 0\n",
    "        for review in self.train_data:  #each user item id combo\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            if e == exp:  #only take the values pertaining the current level\n",
    "                tempsum += (self.pred_e(user,item,e) - review[\"review/score\"])\n",
    "        \n",
    "        tempsum /= self.Ntrain\n",
    "        \n",
    "        #regularization term\n",
    "        tempsum += self.Lambda1*self.alpha[exp]\n",
    "        \n",
    "        if exp == self.E-1:\n",
    "            tempsum += self.Lambda2 * (self.alpha[exp] - self.alpha[exp-1])\n",
    "        elif exp == 0:\n",
    "            tempsum += self.Lambda2 * (self.alpha[exp] - self.alpha[exp+1])\n",
    "        else:\n",
    "            tempsum += self.Lambda2 * (2*self.alpha[exp] - self.alpha[exp-1]  - self.alpha[exp+1])\n",
    "        return tempsum\n",
    "    \n",
    "    def compute_gradient_wrt_Bu(self,e):\n",
    "        ''' Compute gradient of objective with respect to Bu parameter'''\n",
    "        Bu_grad = {}\n",
    "        for user in self.Bu[e]: \n",
    "            total = 0.0\n",
    "            for item in self.Iu[user]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total += (self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Bu[e][user]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Bu[e][user] - self.Bu[e-1][user])\n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Bu[e][user] - self.Bu[e+1][user])\n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Bu[e][user] - self.Bu[e-1][user]  - self.Bu[e+1][user])\n",
    "            Bu_grad[user] = total\n",
    "        return Bu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Bi(self,e):\n",
    "        ''' Compute gradient of objective with respect to Bi parameter'''\n",
    "        Bi_grad = {}\n",
    "        for item in self.Bi[e]:\n",
    "            total = 0.0\n",
    "            for user in self.Ui[item]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total +=  (self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Bi[e][item]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Bi[e][item] - self.Bi[e-1][item])\n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Bi[e][item] - self.Bi[e+1][item])\n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Bi[e][item] - self.Bi[e-1][item]  - self.Bi[e+1][item])\n",
    "            Bi_grad[item] = total\n",
    "        return Bi_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Gu(self,e):\n",
    "        ''' Compute gradient of objective with respect to Gu parameter'''\n",
    "        Gu_grad  = {} \n",
    "        for user in self.Gu[e]:   \n",
    "            total = np.zeros((1,self.k)) \n",
    "            for item in self.Iu[user]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total+= np.multiply(self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"],\\\n",
    "                            self.Gi[e][item])\n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Gu[e][user]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Gu[e][user] - self.Gu[e-1][user]) \n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Gu[e][user] - self.Gu[e+1][user]) \n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Gu[e][user] - self.Gu[e-1][user]  - self.Gu[e+1][user])\n",
    "            Gu_grad[user] = total.copy()\n",
    "        return Gu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Gi(self,e):\n",
    "        ''' Compute gradient of objective with respect to Gi parameter'''\n",
    "        Gi_grad = {}\n",
    "        for item in self.Gi[e]:\n",
    "            total = np.zeros((1,self.k))\n",
    "            for user in self.Ui[item]:\n",
    "                if self.eui[user][item] == e:\n",
    "\n",
    "                    total+= np.multiply(self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"],\\\n",
    "                                self.Gu[e][user])\n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Gi[e][item]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Gi[e][item] - self.Gi[e-1][item])\n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Gi[e][item] - self.Gi[e][item]) \n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Gi[e][item] - self.Gi[e-1][item]  - self.Gi[e+1][item])\n",
    "            Gi_grad[item] = total.copy()\n",
    "        return Gi_grad\n",
    "    \n",
    "        \n",
    "    def deepish_copy(self,org):\n",
    "        '''much, much faster than deepcopy, for a dict of the simple python types.'''\n",
    "        out = dict().fromkeys(org)\n",
    "        for k,v in org.items():\n",
    "            try:\n",
    "                out[k] = v.copy()   # dicts, sets\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    out[k] = v[:]   # lists, tuples, strings, unicode\n",
    "                except TypeError:\n",
    "                    out[k] = v      # ints\n",
    "\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfmObj = ExpertiseLFM(train,Iu, Ui,quickmap,distinct_user_set,distinct_item_set,5,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Objective function value: 860568.1384148761\n",
      "0 Objective value: 710272.2823469071\n",
      "1 Objective value: 106161.61723093552\n",
      "2 Objective value: 24991.502673103772\n",
      "3 Objective value: 1883.2286103063877\n",
      "4 Objective value: 660.7436159156289\n",
      "5 Objective value: 8.738692503028675\n",
      "6 Objective value: 2.990815129697837\n",
      "7 Objective value: 1.0963730616452478\n",
      "8 Objective value: 0.4179673448355708\n",
      "9 Objective value: 0.40978073456530195\n"
     ]
    }
   ],
   "source": [
    "lfmObj.als(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Objective function value: 880208.1080163699\n",
      "0 Objective value: 728833.9027478835\n",
      "1 Objective value: 108207.58523556212\n",
      "2 Objective value: 24787.280796043397\n",
      "3 Objective value: 1950.2537881528115\n",
      "4 Objective value: 672.119160097023\n",
      "5 Objective value: 9.154300848019473\n",
      "6 Objective value: 3.1066645595098357\n",
      "7 Objective value: 1.0330595149330162\n",
      "8 Objective value: 0.3473650732783926\n",
      "9 Objective value: 0.3329269557337709\n",
      "10 Objective value: 0.32670700228618477\n",
      "11 Objective value: 0.32629803332274704\n",
      "12 Objective value: 0.32598298158129635\n",
      "[3.2888581820523148, 3.2908307625414177, 3.2933762948906051, 3.298336639988237, 3.3017812421983144]\n",
      "user: VA Homebrewer start level: 0 end level: 4\n",
      "user: LagerLove start level: 1 end level: 4\n",
      "user: JJClark start level: 2 end level: 4\n",
      "user: TikiE start level: 0 end level: 4\n",
      "user: rakkasan start level: 0 end level: 0\n",
      "Number of experience levels changed:2012023\n",
      "Objective function value: 0.3244345553669969\n",
      "Iteration 2:\n",
      "Objective function value: 0.3244345553669969\n",
      "0 Objective value: 0.3185846506327785\n",
      "1 Objective value: 0.31766259585884604\n",
      "[3.2352674519597966, 3.2779138578021798, 3.2953775460283472, 3.3139245467406706, 3.3573528283958418]\n",
      "user: VA Homebrewer start level: 0 end level: 4\n",
      "user: LagerLove start level: 1 end level: 4\n",
      "user: JJClark start level: 2 end level: 4\n",
      "user: TikiE start level: 0 end level: 4\n",
      "user: rakkasan start level: 0 end level: 0\n",
      "Number of experience levels changed:233439\n",
      "Objective function value: 0.3175952607177297\n",
      "Iteration 3:\n",
      "Objective function value: 0.3175952607177297\n",
      "[3.2352674519597966, 3.2779138578021798, 3.2953775460283472, 3.3139245467406706, 3.3573528283958418]\n",
      "user: VA Homebrewer start level: 0 end level: 4\n",
      "user: LagerLove start level: 1 end level: 4\n",
      "user: JJClark start level: 2 end level: 4\n",
      "user: TikiE start level: 0 end level: 4\n",
      "user: rakkasan start level: 0 end level: 0\n",
      "Number of experience levels changed:0\n",
      "Objective function value: 0.3175952607177297\n",
      "Breaking\n"
     ]
    }
   ],
   "source": [
    "lfmObj.als(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'18186'\n",
      "'27384'\n",
      "'33304'\n",
      "'34717'\n",
      "'54832'\n",
      "'65106'\n",
      "'84699'\n",
      "'108813'\n",
      "'114376'\n",
      "'119595'\n",
      "'120160'\n",
      "'124485'\n",
      "'156825'\n",
      "Warning! Unknown 13 new data rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.62359128935382"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmObj.mse_test(test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
