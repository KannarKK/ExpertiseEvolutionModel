{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: import simplejson as json\n",
    "except ImportError: import json\n",
    "\n",
    "import gzip,codecs,numpy as np,random,copy\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the split dataset into train and test.\n",
    "build the Iu and Ui data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ratebeer_train_random.json\",\"r\") as infile:\n",
    "    train = json.load(infile)\n",
    "infile.close()\n",
    "with open(\"ratebeer_test_random.json\",\"r\") as infile:\n",
    "    test = json.load(infile)\n",
    "infile.close()\n",
    "with open(\"ratebeer_quickmap_random.json\",\"r\") as infile:\n",
    "    quickmap = json.load(infile)\n",
    "infile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704815 4760 2709575\n"
     ]
    }
   ],
   "source": [
    "print(len(train),len(test),len(quickmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iu = dict() #set of products reviewed by users\n",
    "Ui = dict() #set of users who reviewed the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = sorted(train, key = lambda k : k[\"review/time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review in train:\n",
    "        item = review[\"product/productId\"]\n",
    "        user = review[\"review/userId\"]\n",
    "        if item in Ui:\n",
    "            Ui[item].append(user)\n",
    "        else:\n",
    "            Ui[item] = [user]\n",
    "        if user in Iu:\n",
    "            Iu[user].append(item)\n",
    "        else:\n",
    "            Iu[user] = [item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct user and item mapping to integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_user_set = set()\n",
    "distinct_item_set = set()\n",
    "for review in train:\n",
    "    if review[\"review/userId\"] not in distinct_user_set:\n",
    "        distinct_user_set.add(review[\"review/userId\"])\n",
    "    if review[\"product/productId\"] not in distinct_item_set:\n",
    "        distinct_item_set.add(review[\"product/productId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760 110032\n"
     ]
    }
   ],
   "source": [
    "print(len(distinct_user_set), len(distinct_item_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent factor model  -standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LFM(object):\n",
    "    ''' LFM class implements the standard latent factor model of collaborative filtering using matrix factorization\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,train_data, Iu_reg, Ui_reg, userproduct_dict,userset,itemset,k,Lambda):\n",
    "        ''' requires Iu and Ui matrix information, quick mapping of reviews to (user,product) and k for set up\n",
    "        also sets up k fold training data for k-cross validation\n",
    "        '''\n",
    "        \n",
    "        self.Ntrain = len(train_data)               #Number of training samples\n",
    "        self.train_data = train_data                #the train_data used\n",
    "        self.Iu = self.deepish_copy(Iu_reg)         #Iu mapping\n",
    "        self.Ui = self.deepish_copy(Ui_reg)         #Ui mapping\n",
    "        self.quickmap = userproduct_dict            #uses key as (userid-itemid) for quick mapping to required review\n",
    "        self.user_set = userset\n",
    "        self.item_set = itemset\n",
    "        \n",
    "        self.user_map = {}\n",
    "        self.item_map = {}\n",
    "        i=0\n",
    "        for user in self.user_set:\n",
    "            self.user_map[i] = user\n",
    "            i+=1\n",
    "        i=0\n",
    "        for item in self.item_set:\n",
    "            self.item_map[i] = item\n",
    "            i+=1\n",
    "            \n",
    "        #hyperparameters\n",
    "        self.Lambda= Lambda               #regularization param\n",
    "        self.k=k                          # number of latent factor dimension (low dimensional repr)\n",
    "        self.final_param = self.init_theta()  #initialize the current final_param to some value.\n",
    "        \n",
    "        \n",
    "    def init_theta(self):\n",
    "        ''' Initializes the parameter of the standard model\n",
    "        flat_theta = <alpha, Bu, Bi, Gu,Gu>\n",
    "        '''\n",
    "        flat_theta = []\n",
    "        #baseline predictors\n",
    "        self.alpha = 0                    #global offset\n",
    "        flat_theta.append(self.alpha)\n",
    "        \n",
    "        self.Bu = dict()                  #user bias initialized randomly\n",
    "        self.Bi = dict()                  #item bias initialized randomly\n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu[self.user_map[i]] =np.random.random(1).item() \n",
    "            flat_theta.append(self.Bu[self.user_map[i]])\n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi[self.item_map[i]] = np.random.random(1).item() \n",
    "            flat_theta.append(self.Bi[self.item_map[i]])\n",
    "        \n",
    "        #Latent factor variables initialized from a uniform distribution\n",
    "        self.Gu = dict()                      #user latent factor vector repr\n",
    "        self.Gi = dict()                      #item latent factor vector repr\n",
    "        \n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Gu[self.user_map[i]] = np.random.uniform(0,1,(1,self.k)) \n",
    "            flat_theta.extend(np.array(list(self.Gu[self.user_map[i]])).flatten())\n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Gi[self.item_map[i]] = np.random.uniform(0,1,(1,self.k)) \n",
    "            flat_theta.extend(np.array(list(self.Gi[self.item_map[i]])).flatten())\n",
    "        \n",
    "        self.totalparams = 1 + len(self.user_set) + len(self.item_set) +\\\n",
    "                        self.k*(len(self.user_set) + len(self.item_set))\n",
    "        return np.array(flat_theta)\n",
    "    \n",
    "    \n",
    "    def retrieve_theta_components(self,theta):\n",
    "        self.alpha = theta[0]\n",
    "        j=1\n",
    "        for i in range(len(self.user_set)):\n",
    "            self.Bu[self.user_map[i]] = theta[j]\n",
    "            j+=1\n",
    "        for i in range(len(self.item_set)):\n",
    "            self.Bi[self.item_map[i]] = theta[j]\n",
    "            j+=1\n",
    "        for i in range(len(self.user_set)):\n",
    "            self.Gu[self.user_map[i]] = np.array(theta[j:j+self.k])\n",
    "            j += self.k\n",
    "        for i in range(len(self.item_set)):\n",
    "            self.Gi[self.item_map[i]] = np.array(theta[j:j+self.k])\n",
    "            j+=self.k\n",
    "        #print(j, self.final_param,len(theta))\n",
    "        if j!= len(theta):\n",
    "            print(\"Something went wrong. Not all theta values were used\")\n",
    "        \n",
    "    def pred(self,user,item):\n",
    "        ''' calculates the current prediction by the model for the rating of user for the given item'''\n",
    "        return self.alpha + self.Bu[user] + self.Bi[item]+ np.asscalar(np.dot(self.Gu[user], self.Gi[item].T))\n",
    "    \n",
    "    def f(self,theta):\n",
    "        '''Calculates the value of the objective function (loss) on the training data. \n",
    "            Note that the training error is not MSE '''\n",
    "        #retrieve the individual components of theta\n",
    "        self.retrieve_theta_components(theta)\n",
    "        error = 0\n",
    "        for review in self.train_data:\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            error += (self.pred(user,item) - review[\"review/score\"])**2\n",
    "        error/=self.Ntrain\n",
    "        #regularization terms \n",
    "        Bu_np = np.array(list(self.Bu.values()))\n",
    "        Bi_np = np.array(list(self.Bi.values()))\n",
    "        reg_complexity = np.sum(np.square(Bu_np)) + np.sum(np.square(Bi_np))\n",
    "        for user in self.Gu:\n",
    "            reg_complexity += np.linalg.norm(self.Gu[user])**2\n",
    "        for item in self.Gi:\n",
    "            reg_complexity += np.linalg.norm(self.Gi[item])**2\n",
    "        total_mse = error + self.Lambda * reg_complexity\n",
    "        return total_mse/2.0\n",
    "    \n",
    "    def fprime_one_func(self,theta):\n",
    "        self.retrieve_theta_components(theta)\n",
    "        flat_gradient = []\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        \n",
    "        self.alpha_grad = 0                              \n",
    "        self.Bu_grad = dict()                                      \n",
    "        self.Bi_grad = dict()                                     \n",
    "        self.Gu_grad = dict()                      \n",
    "        self.Gi_grad = dict()   \n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu_grad[self.user_map[i]] = 0.0\n",
    "            self.Gu_grad[self.user_map[i]] = np.zeros((1,self.k)) \n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi_grad[self.item_map[i]] = 0.0\n",
    "            self.Gi_grad[self.item_map[i]] = np.zeros((1,self.k))\n",
    "        \n",
    "        for review in self.train_data:\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            delta = self.pred(user,item) - review[\"review/score\"]\n",
    "            delta /= self.Ntrain\n",
    "            self.alpha_grad += delta\n",
    "            self.Bu_grad[user]+= delta\n",
    "            self.Bi_grad[item]+= delta\n",
    "            self.Gu_grad[user]+= delta * self.Gi[item]\n",
    "            self.Gi_grad[item]+= delta * self.Gu[user]\n",
    "        \n",
    "        for user in self.user_set:\n",
    "            self.Bu_grad[user] += self.Lambda * self.Bu[user]\n",
    "            self.Gu_grad[user] += self.Lambda * self.Gu[user]\n",
    "        for item in self.item_set:\n",
    "            self.Bi_grad[item] += self.Lambda * self.Bi[item]\n",
    "            self.Gi_grad[item] += self.Lambda * self.Gi[item]\n",
    "        \n",
    "        flat_gradient.append(self.alpha_grad)\n",
    "        for i in range(len(self.user_set)):\n",
    "            flat_gradient.append(self.Bu_grad[self.user_map[i]])\n",
    "        for i in range(len(self.item_set)):\n",
    "            flat_gradient.append(self.Bi_grad[self.item_map[i]])\n",
    "        for i in range(len(self.user_set)):\n",
    "            flat_gradient.extend(np.array(self.Gu_grad[self.user_map[i]]).flatten())\n",
    "        for i in range(len(self.item_set)):\n",
    "            flat_gradient.extend(np.array(self.Gi_grad[self.item_map[i]]).flatten())\n",
    "        \n",
    "        return np.array(flat_gradient)\n",
    "        \n",
    "    \n",
    "    def fprime(self, theta):\n",
    "        self.retrieve_theta_components(theta)\n",
    "        flat_gradient = [self.compute_gradient_wrt_alpha()]\n",
    "        Bu_grad = self.compute_gradient_wrt_Bu()\n",
    "        Bi_grad = self.compute_gradient_wrt_Bi()\n",
    "        Gu_grad = self.compute_gradient_wrt_Gu()\n",
    "        Gi_grad = self.compute_gradient_wrt_Gi()\n",
    "        for i in range(len(self.user_set)):\n",
    "            flat_gradient.append(Bu_grad[self.user_map[i]])\n",
    "        for i in range(len(self.item_set)):\n",
    "            flat_gradient.append(Bi_grad[self.item_map[i]])\n",
    "        for i in range(len(self.user_set)):\n",
    "            flat_gradient.extend(np.array(Gu_grad[self.user_map[i]]).flatten())\n",
    "        for i in range(len(self.item_set)):\n",
    "            flat_gradient.extend(np.array(Gi_grad[self.item_map[i]]).flatten())\n",
    "        return np.array(flat_gradient)\n",
    "    \n",
    "    def vanilla_gd(self,eta):\n",
    "        flat_theta_guess =np.array([0]*self.totalparams, dtype = np.float64)\n",
    "        for i in range(1000):\n",
    "            flat_gradient = self.fprime(flat_theta_guess)\n",
    "            flat_theta_guess -= eta*flat_gradient\n",
    "            print(\"{} U : Objective value: {}\".format(i,self.f(flat_theta_guess)))\n",
    "    \n",
    "    def call(self,theta):\n",
    "        print(\"{} Objective value: {}\".format(self.i, self.f(theta)))\n",
    "        self.i+=1\n",
    "    \n",
    "    def objectiveloss_lbfgs(self,grad_tolerance,fac):\n",
    "        self.i =0;\n",
    "        flat_theta_guess = self.final_param  #start with the initial guess or the one made by previous call to func\n",
    "        flat_theta,value,d = opt.fmin_l_bfgs_b(self.f,flat_theta_guess,self.fprime_one_func,\\\n",
    "                                               pgtol = grad_tolerance,disp=True,\\\n",
    "                                              callback = self.call, iprint=0)\n",
    "        print(\"Value of ojective function {} at pgtol={}\".format(value,grad_tolerance))\n",
    "        self.final_param = flat_theta\n",
    "    \n",
    "    def mse_test(self,test_data):\n",
    "        ''' Uses Mean Squared Error as evaluation metric on test data provided by user'''\n",
    "        self.retrieve_theta_components(self.final_param)\n",
    "        error = 0\n",
    "        unknown_data_count =0;\n",
    "        for review in test_data:\n",
    "            if review[\"review/userId\"] in self.Bu and review[\"product/productId\"] in self.Bi:\n",
    "                user = review[\"review/userId\"]\n",
    "                item = review[\"product/productId\"]\n",
    "                error += ( self.pred(user,item) - review[\"review/score\"] )**2\n",
    "            else: \n",
    "                unknown_data_count+=1\n",
    "        if unknown_data_count>0:\n",
    "            print(\"Warning! Unknown {} new data rows\".format(unknown_data_count))\n",
    "        return error / (len(test_data) - unknown_data_count)\n",
    "    \n",
    "    def compute_gradient_wrt_alpha(self):\n",
    "        ''' Compute gradient of objective with respect to alpha parameter'''\n",
    "        tempsum = 0\n",
    "        for review in self.train_data:  #each user item id combo\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            tempsum += (self.pred(user,item) - review[\"review/score\"])\n",
    "        return tempsum/self.Ntrain\n",
    "    \n",
    "    def compute_gradient_wrt_Bu(self):\n",
    "        ''' Compute gradient of objective with respect to Bu parameter'''\n",
    "        Bu_grad = {}\n",
    "        for user in self.Bu:   \n",
    "            total = 0.0\n",
    "            for item in self.Iu[user]:\n",
    "                total+= (self.pred(user,item) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total = total/self.Ntrain + self.Lambda*self.Bu[user]\n",
    "            Bu_grad[user] = total\n",
    "        return Bu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Bi(self):\n",
    "        ''' Compute gradient of objective with respect to Bi parameter'''\n",
    "        Bi_grad = {}\n",
    "        for item in self.Bi:\n",
    "            total = 0.0\n",
    "            for user in self.Ui[item]:\n",
    "                total+= (self.pred(user,item) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total = total/self.Ntrain + self.Lambda*self.Bi[item]\n",
    "            Bi_grad[item] = total\n",
    "        return Bi_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Gu(self):\n",
    "        ''' Compute gradient of objective with respect to Gu parameter'''\n",
    "        Gu_grad  = {} \n",
    "        for user in self.Gu:   \n",
    "            total = np.zeros((1,self.k)) \n",
    "            for item in self.Iu[user]:\n",
    "                Rui = self.quickmap[user+'-'+item][\"review/score\"]\n",
    "                total+= np.multiply(self.pred(user,item)- Rui, self.Gi[item])\n",
    "            total = total/self.Ntrain + self.Lambda*self.Gu[user]\n",
    "            Gu_grad[user] = total.copy()\n",
    "        #print(\"Gu grad lenght: {}\".format(len(np.array(list(Gu_grad.values())).flatten())))\n",
    "        return Gu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Gi(self):\n",
    "        ''' Compute gradient of objective with respect to Gi parameter'''\n",
    "        Gi_grad = {}\n",
    "        for item in self.Gi:\n",
    "            total = np.zeros((1,self.k))\n",
    "            for user in self.Ui[item]:\n",
    "                Rui = self.quickmap[user+'-'+item][\"review/score\"]\n",
    "                total+= np.multiply(self.pred(user,item)- Rui, self.Gu[user])\n",
    "            total = total/self.Ntrain + self.Lambda*self.Gi[item]\n",
    "            Gi_grad[item] = total.copy()\n",
    "       \n",
    "        #print(\"Gi grad lenght: {}\".format(len(np.array(list(Gi_grad.values())).flatten())))\n",
    "        return Gi_grad\n",
    "    \n",
    "        \n",
    "    def deepish_copy(self,org):\n",
    "        '''\n",
    "        much, much faster than deepcopy, for a dict of the simple python types.\n",
    "        '''\n",
    "        out = dict().fromkeys(org)\n",
    "        for k,v in org.items():\n",
    "            try:\n",
    "                out[k] = v.copy()   # dicts, sets\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    out[k] = v[:]   # lists, tuples, strings, unicode\n",
    "                except TypeError:\n",
    "                    out[k] = v      # ints\n",
    "\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfmObj = LFM(train,Iu, Ui,quickmap,distinct_user_set,distinct_item_set,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad1 = lfmObj.fprime(lfmObj.final_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(np.subtract(grad1,grad2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad2 = lfmObj.fprime_one_func(lfmObj.final_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Objective value: 77684.61485782327\n",
      "1 Objective value: 0.8692116750404012\n",
      "2 Objective value: 0.32655058625302247\n",
      "3 Objective value: 0.32599165007545655\n",
      "4 Objective value: 0.325991505536594\n",
      "Value of ojective function 0.325991505536594 at pgtol=1e-05\n"
     ]
    }
   ],
   "source": [
    "lfmObj.objectiveloss_lbfgs(1e-5,1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product/productId': '0657745316',\n",
       " 'review/score': 5.0,\n",
       " 'review/userId': 'A1ZQZ8RJS1XVTX'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finefood_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Unknown 13 new data rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81706664819601593"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmObj.mse_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.301868818887046"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmObj.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"ratebeer_lfm_results\", lfmObj.final_param)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
