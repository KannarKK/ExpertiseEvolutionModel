{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: import simplejson as json\n",
    "except ImportError: import json\n",
    "\n",
    "import gzip,codecs,numpy as np,random,copy\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the split dataset into train and test.\n",
    "build the Iu and Ui data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704815 4760 2709575\n"
     ]
    }
   ],
   "source": [
    "#with open(\"finefood_train_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_train_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_train_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"finefood_train_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"ratebeer_train_lastrating.json\",\"r\") as infile:\n",
    "with open(\"ratebeer_train_random.json\",\"r\") as infile:\n",
    "    train = json.load(infile)\n",
    "infile.close()\n",
    "#with open(\"finefood_test_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_test_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_test_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"finefood_test_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"ratebeer_test_lastrating.json\",\"r\") as infile:\n",
    "with open(\"ratebeer_test_random.json\",\"r\") as infile:\n",
    "    test = json.load(infile)\n",
    "infile.close()\n",
    "#with open(\"finefood_quickmap_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_quickmap_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_quickmap_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"finefood_quickmap_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"ratebeer_quickmap_lastrating.json\",\"r\") as infile:\n",
    "with open(\"ratebeer_quickmap_random.json\",\"r\") as infile:\n",
    "    quickmap = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "print(len(train),len(test),len(quickmap))\n",
    "train = sorted(train, key = lambda k : int(k[\"review/time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iu = dict() #set of products reviewed by users\n",
    "Ui = dict() #set of users who reviewed the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review in train:\n",
    "        item = review[\"product/productId\"]\n",
    "        user = review[\"review/userId\"]\n",
    "        if item in Ui:\n",
    "            Ui[item].append(user)\n",
    "        else:\n",
    "            Ui[item] = [user]\n",
    "        if user in Iu:\n",
    "            Iu[user].append(item)\n",
    "        else:\n",
    "            Iu[user] = [item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct user and item mapping to integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_user_set = set()\n",
    "distinct_item_set = set()\n",
    "for review in train:\n",
    "    if review[\"review/userId\"] not in distinct_user_set:\n",
    "        distinct_user_set.add(review[\"review/userId\"])\n",
    "    if review[\"product/productId\"] not in distinct_item_set:\n",
    "        distinct_item_set.add(review[\"product/productId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760 110032\n"
     ]
    }
   ],
   "source": [
    "print(len(distinct_user_set), len(distinct_item_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"finefood_user_map_random.json\",'r') as infile:\n",
    "with open(\"ratebeer_user_map_random.json\",'r') as infile:\n",
    "#with open(\"ratebeer_user_map_lastrating.json\",'r') as infile:\n",
    "        user_map = json.load(infile)\n",
    "#print(\"File {} written\".format(\"ratebeer_user_map_lastrating.json\"))\n",
    "infile.close()\n",
    "#with open(\"finefood_item_map_random.json\",'r') as infile:\n",
    "with open(\"ratebeer_item_map_random.json\",'r') as infile:\n",
    "#with open(\"ratebeer_item_map_lastrating.json\",'r') as infile:\n",
    "        item_map = json.load(infile)\n",
    "#print(\"File {} written\".format(\"ratebeer_item_map_lastrating.json\"))\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_map_int = {}\n",
    "for key in user_map:\n",
    "    user_map_int[int(key)] = user_map[key]\n",
    "item_map_int = {}\n",
    "for key in item_map:\n",
    "    item_map_int[int(key)] = item_map[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent factor model  -standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LFM(object):\n",
    "    ''' LFM class implements the standard latent factor model of collaborative filtering using matrix factorization\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,train_data, Iu_reg, Ui_reg, userproduct_dict,userset,itemset,usermap,itemmap,k,Lambda):\n",
    "        ''' requires Iu and Ui matrix information, quick mapping of reviews to (user,product) and k for set up\n",
    "        also sets up k fold training data for k-cross validation\n",
    "        '''\n",
    "        \n",
    "        self.Ntrain = len(train_data)               #Number of training samples\n",
    "        self.train_data = train_data                #the train_data used\n",
    "        self.Iu = self.deepish_copy(Iu_reg)         #Iu mapping\n",
    "        self.Ui = self.deepish_copy(Ui_reg)         #Ui mapping\n",
    "        self.quickmap = userproduct_dict            #uses key as (userid-itemid) for quick mapping to required review\n",
    "        self.user_set = userset\n",
    "        self.item_set = itemset\n",
    "        \n",
    "        self.user_map = usermap\n",
    "        self.item_map = itemmap\n",
    "            \n",
    "        #hyperparameters\n",
    "        self.Lambda= Lambda               #regularization param\n",
    "        self.k=k                          # number of latent factor dimension (low dimensional repr)\n",
    "        self.final_param = self.init_theta()  #initialize the current final_param to some value.\n",
    "        \n",
    "        \n",
    "    def init_theta(self):\n",
    "        ''' Initializes the parameter of the standard model\n",
    "        flat_theta = <alpha, Bu, Bi, Gu,Gu>\n",
    "        '''\n",
    "        flat_theta = []\n",
    "        #baseline predictors\n",
    "        self.alpha = 0                    #global offset\n",
    "        flat_theta.append(self.alpha)\n",
    "        \n",
    "        self.Bu = dict()                  #user bias initialized randomly\n",
    "        self.Bi = dict()                  #item bias initialized randomly\n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu[self.user_map[i]] =np.random.random(1).item() \n",
    "            flat_theta.append(self.Bu[self.user_map[i]])\n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi[self.item_map[i]] = np.random.random(1).item() \n",
    "            flat_theta.append(self.Bi[self.item_map[i]])\n",
    "        \n",
    "        self.totalparams = 1 + len(self.user_set) + len(self.item_set) \n",
    "        return np.array(flat_theta)\n",
    "    \n",
    "    \n",
    "    def retrieve_theta_components(self,theta):\n",
    "        self.alpha = theta[0]\n",
    "        j=1\n",
    "        for i in range(len(self.user_set)):\n",
    "            self.Bu[self.user_map[i]] = theta[j]\n",
    "            j+=1\n",
    "        for i in range(len(self.item_set)):\n",
    "            self.Bi[self.item_map[i]] = theta[j]\n",
    "            j+=1\n",
    "        if j!= len(theta):\n",
    "            print(\"Something went wrong. Not all theta values were used\")\n",
    "        \n",
    "    def pred(self,user,item):\n",
    "        ''' calculates the current prediction by the model for the rating of user for the given item'''\n",
    "        return self.alpha + self.Bu[user] + self.Bi[item]\n",
    "    \n",
    "    def f(self,theta):\n",
    "        '''Calculates the value of the objective function (loss) on the training data. \n",
    "            Note that the training error is not MSE '''\n",
    "        #retrieve the individual components of theta\n",
    "        self.retrieve_theta_components(theta)\n",
    "        error = 0\n",
    "        for review in self.train_data:\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            error += (self.pred(user,item) - review[\"review/score\"])**2\n",
    "        error/=self.Ntrain\n",
    "        #regularization terms \n",
    "        Bu_np = np.array(list(self.Bu.values()))\n",
    "        Bi_np = np.array(list(self.Bi.values()))\n",
    "        reg_complexity = np.sum(np.square(Bu_np)) + np.sum(np.square(Bi_np))\n",
    "    \n",
    "        total_mse = error + self.Lambda * reg_complexity\n",
    "        return total_mse/2.0\n",
    "    \n",
    "    def fprime_one_func(self,theta):\n",
    "        self.retrieve_theta_components(theta)\n",
    "        flat_gradient = []\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        \n",
    "        self.alpha_grad = 0                              \n",
    "        self.Bu_grad = dict()                                      \n",
    "        self.Bi_grad = dict()                                     \n",
    "          \n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu_grad[self.user_map[i]] = 0.0\n",
    "            \n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi_grad[self.item_map[i]] = 0.0\n",
    " \n",
    "        \n",
    "        for review in self.train_data:\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            delta = self.pred(user,item) - review[\"review/score\"]\n",
    "            delta /= self.Ntrain\n",
    "            self.alpha_grad += delta\n",
    "            self.Bu_grad[user]+= delta\n",
    "            self.Bi_grad[item]+= delta\n",
    "        \n",
    "        for user in self.user_set:\n",
    "            self.Bu_grad[user] += self.Lambda * self.Bu[user]\n",
    "            \n",
    "        for item in self.item_set:\n",
    "            self.Bi_grad[item] += self.Lambda * self.Bi[item]\n",
    "\n",
    "        \n",
    "        flat_gradient.append(self.alpha_grad)\n",
    "        for i in range(len(self.user_set)):\n",
    "            flat_gradient.append(self.Bu_grad[self.user_map[i]])\n",
    "        for i in range(len(self.item_set)):\n",
    "            flat_gradient.append(self.Bi_grad[self.item_map[i]])\n",
    "\n",
    "        return np.array(flat_gradient)\n",
    "    \n",
    "    def call(self,theta):\n",
    "        print(\"{} Objective value: {}\".format(self.i, self.f(theta)))\n",
    "        self.i+=1\n",
    "    \n",
    "    def objectiveloss_lbfgs(self,grad_tolerance,fac):\n",
    "        self.i =0;\n",
    "        flat_theta_guess = self.final_param  #start with the initial guess or the one made by previous call to func\n",
    "        flat_theta,value,d = opt.fmin_l_bfgs_b(self.f,flat_theta_guess,self.fprime_one_func,\\\n",
    "                                               pgtol = grad_tolerance,disp=True,\\\n",
    "                                             callback = self.call, iprint=0)\n",
    "        print(\"Value of ojective function {} at pgtol={}\".format(value,grad_tolerance))\n",
    "        self.final_param = flat_theta\n",
    "    \n",
    "    def mse_test(self,test_data):\n",
    "        ''' Uses Mean Squared Error as evaluation metric on test data provided by user'''\n",
    "        self.retrieve_theta_components(self.final_param)\n",
    "        error = 0\n",
    "        unknown_data_count =0;\n",
    "        for review in test_data:\n",
    "            if review[\"review/userId\"] in self.Bu and review[\"product/productId\"] in self.Bi:\n",
    "                user = review[\"review/userId\"]\n",
    "                item = review[\"product/productId\"]\n",
    "                error += (self.pred(user,item) - review[\"review/score\"] )**2\n",
    "            else: \n",
    "                unknown_data_count+=1\n",
    "        if unknown_data_count>0:\n",
    "            print(\"Warning! Unknown {} new data rows\".format(unknown_data_count))\n",
    "        return error / (len(test_data) - unknown_data_count)\n",
    "   \n",
    "    def deepish_copy(self,org):\n",
    "        '''\n",
    "        much, much faster than deepcopy, for a dict of the simple python types.\n",
    "        '''\n",
    "        out = dict().fromkeys(org)\n",
    "        for k,v in org.items():\n",
    "            try:\n",
    "                out[k] = v.copy()   # dicts, sets\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    out[k] = v[:]   # lists, tuples, strings, unicode\n",
    "                except TypeError:\n",
    "                    out[k] = v      # ints\n",
    "\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfmObj = LFM(train,Iu, Ui,quickmap,distinct_user_set,distinct_item_set,user_map_int,item_map_int, 5,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Objective value: 20.428455947081567\n",
      "1 Objective value: 19.50416622149925\n",
      "2 Objective value: 19.312060726932696\n",
      "3 Objective value: 16.91199215836161\n",
      "4 Objective value: 13.142792830633583\n",
      "5 Objective value: 6.856081699338087\n",
      "6 Objective value: 2.039378145941633\n",
      "7 Objective value: 0.5356946428992466\n",
      "8 Objective value: 0.3948612506757086\n",
      "9 Objective value: 0.38982840266660845\n",
      "10 Objective value: 0.37874058054010645\n",
      "11 Objective value: 0.32546565949127376\n",
      "12 Objective value: 0.2948140899776007\n",
      "13 Objective value: 0.2904529011359158\n",
      "14 Objective value: 0.2898493106914063\n",
      "15 Objective value: 0.28982081587081693\n",
      "16 Objective value: 0.28979445922837427\n",
      "17 Objective value: 0.28945115778729763\n",
      "18 Objective value: 0.28940231647799824\n",
      "19 Objective value: 0.28939307504522277\n",
      "20 Objective value: 0.2893836090171044\n",
      "21 Objective value: 0.2893740361127268\n",
      "22 Objective value: 0.2893631230192639\n",
      "23 Objective value: 0.28935439488209264\n",
      "24 Objective value: 0.28934601168868257\n",
      "25 Objective value: 0.28933740900131216\n",
      "26 Objective value: 0.2893370067283823\n",
      "27 Objective value: 0.28933350576976946\n",
      "28 Objective value: 0.28933264622435023\n",
      "29 Objective value: 0.2893322334015475\n",
      "30 Objective value: 0.2893315963349464\n",
      "31 Objective value: 0.28933021757069066\n",
      "32 Objective value: 0.289329277906493\n",
      "33 Objective value: 0.28932747304540446\n",
      "34 Objective value: 0.2893265923834148\n",
      "35 Objective value: 0.28932435598570727\n",
      "36 Objective value: 0.28932363411522183\n",
      "37 Objective value: 0.28932334048419023\n",
      "38 Objective value: 0.28932324765016043\n",
      "39 Objective value: 0.289323235131841\n",
      "40 Objective value: 0.28932320290509994\n",
      "41 Objective value: 0.28932313885774547\n",
      "42 Objective value: 0.2893230653577113\n",
      "43 Objective value: 0.2893230293222203\n",
      "44 Objective value: 0.2893230204334919\n",
      "45 Objective value: 0.2893230031047134\n",
      "Value of ojective function 0.2893230031047134 at pgtol=1e-05\n"
     ]
    }
   ],
   "source": [
    "lfmObj.objectiveloss_lbfgs(1e-5,1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Unknown 13 new data rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66164794509092251"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmObj.mse_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3021826813685182"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmObj.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"ratebeer_standard_lfm_results\", lfmObj.final_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46156493966674039"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lfmObj.Bi.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
