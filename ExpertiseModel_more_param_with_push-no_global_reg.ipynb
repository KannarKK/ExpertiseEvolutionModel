{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses push model concept (also works :D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: import simplejson as json\n",
    "except ImportError: import json\n",
    "\n",
    "import gzip,codecs,numpy as np,random,copy\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704815 4760 2709575\n"
     ]
    }
   ],
   "source": [
    "#with open(\"finefood_train_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_train_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_train_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"finefood_train_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"ratebeer_train_lastrating.json\",\"r\") as infile:\n",
    "with open(\"ratebeer_train_random.json\",\"r\") as infile:\n",
    "    train = json.load(infile)\n",
    "infile.close()\n",
    "#with open(\"finefood_test_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_test_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_test_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"finefood_test_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"ratebeer_test_lastrating.json\",\"r\") as infile:\n",
    "with open(\"ratebeer_test_random.json\",\"r\") as infile:\n",
    "    test = json.load(infile)\n",
    "infile.close()\n",
    "#with open(\"finefood_quickmap_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_quickmap_random.json\",\"r\") as infile:\n",
    "#with open(\"beeradvocate_quickmap_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"finefood_quickmap_lastrating.json\",\"r\") as infile:\n",
    "#with open(\"ratebeer_quickmap_lastrating.json\",\"r\") as infile:\n",
    "with open(\"ratebeer_quickmap_random.json\",\"r\") as infile:\n",
    "    quickmap = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "print(len(train),len(test),len(quickmap))\n",
    "train = sorted(train, key = lambda k : int(k[\"review/time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iu = dict() #set of products reviewed by users\n",
    "Ui = dict() #set of users who reviewed the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review in train:\n",
    "        item = review[\"product/productId\"]\n",
    "        user = review[\"review/userId\"]\n",
    "        if item in Ui:\n",
    "            Ui[item].append(user)\n",
    "        else:\n",
    "            Ui[item] = [user]\n",
    "        if user in Iu:\n",
    "            Iu[user].append(item)\n",
    "        else:\n",
    "            Iu[user] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760\n"
     ]
    }
   ],
   "source": [
    "print(len(Iu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4760 110032\n"
     ]
    }
   ],
   "source": [
    "distinct_user_set = set()\n",
    "distinct_item_set = set()\n",
    "for review in train:\n",
    "    if review[\"review/userId\"] not in distinct_user_set:\n",
    "        distinct_user_set.add(review[\"review/userId\"])\n",
    "    if review[\"product/productId\"] not in distinct_item_set:\n",
    "        distinct_item_set.add(review[\"product/productId\"])\n",
    "print(len(distinct_user_set), len(distinct_item_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(\"finefood_user_map_random.json\",'r') as infile:\n",
    "#with open(\"finefood_user_map_lastrating.json\",'r') as infile:\n",
    "#with open(\"beeradvocate_user_map_random.json\",'r') as infile:\n",
    "#with open(\"beeradvocate_user_map_lastrating.json\",'r') as infile:\n",
    "#with open(\"ratebeer_user_map_lastrating.json\",'r') as infile:\n",
    "with open(\"ratebeer_user_map_random.json\",'r') as infile:\n",
    "        user_map = json.load(infile)\n",
    "infile.close()\n",
    "#with open(\"finefood_item_map_random.json\",'r') as infile:\n",
    "#with open(\"finefood_item_map_lastrating.json\",'r') as infile:\n",
    "#with open(\"beeradvocate_item_map_random.json\",'r') as infile:\n",
    "#with open(\"beeradvocate_item_map_lastrating.json\",'r') as infile:\n",
    "#with open(\"ratebeer_item_map_lastrating.json\",'r') as infile:\n",
    "with open(\"ratebeer_item_map_random.json\",'r') as infile:\n",
    "        item_map = json.load(infile)\n",
    "infile.close()\n",
    "\n",
    "user_map_int = {}\n",
    "for key in user_map:\n",
    "    user_map_int[int(key)] = user_map[key]\n",
    "item_map_int = {}\n",
    "for key in item_map:\n",
    "    item_map_int[int(key)] = item_map[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expertise modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExpertiseLFM(object):\n",
    "    ''' Expertise LFM class implements the evolution latent factor model of collaborative filtering \n",
    "    using matrix factorization\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,train_data, Iu_reg, Ui_reg, userproduct_dict,userset,itemset,\\\n",
    "                 usermap, itemmap,k,Lambda1,Lambda2,E,mode):\n",
    "        ''' requires Iu and Ui matrix information, quick mapping of reviews to (user,product),\n",
    "         k =number of latent factor dimensions, \n",
    "         lambda1 = reg parameter, lambda2 = smoothing parameter,\n",
    "         E = number of experience levels.\n",
    "        '''\n",
    "        \n",
    "        self.Ntrain = len(train_data)               #Number of training samples\n",
    "        self.train_data = train_data                #training data \n",
    "        self.Iu = self.deepish_copy(Iu_reg)         #Iu mapping  \n",
    "        self.Ui = self.deepish_copy(Ui_reg)         #Ui mapping\n",
    "        self.quickmap = userproduct_dict            #uses key as (userid-itemid) for quick mapping to required review\n",
    "        self.user_set = userset\n",
    "        self.item_set = itemset\n",
    "        \n",
    "        self.user_map = usermap     #mapping for easier transformation from long gradient vector to individual gradients\n",
    "        self.item_map = itemmap\n",
    "        \n",
    "        \n",
    "        #hyperparameters\n",
    "        self.Lambda1 = Lambda1    #regularization param\n",
    "        self.Lambda2 = Lambda2    #smoothing reg param     \n",
    "        self.k = k                # number of latent factor dimension (low dimensional repr)\n",
    "        self.E = E                #number of experience levels\n",
    "        self.mode = mode\n",
    "        self.final_param = self.init_theta()  #current final_parameters\n",
    "        self.init_exp()\n",
    "        \n",
    "    \n",
    "    \n",
    "    def init_theta(self):\n",
    "        ''' Initializes the parameters of E recommender models\n",
    "        \n",
    "        flat_theta = <alpha_G, Bu_G, Bi_G, alpha_e1..E, Bu_e1..E, Bi_e1..E, Gu_e1...E, Gi_e1...E>\n",
    "        '''\n",
    "        flat_theta = []\n",
    "        \n",
    "        rating_arr = [review[\"review/score\"] for review in self.train_data]\n",
    "        avg_rating = np.mean(rating_arr)\n",
    "        self.alpha_G = avg_rating                                 #global offset\n",
    "        self.Bu_G = dict()                                        #user bias (global)\n",
    "        self.Bi_G = dict()                                        #item bias (global)\n",
    "        \n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu_G[self.user_map[i]] = np.random.random(1).item() \n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi_G[self.item_map[i]] = np.random.random(1).item() \n",
    "        \n",
    "        flat_theta.append(self.alpha_G)\n",
    "        flat_theta.extend(list(self.Bu_G.values()))\n",
    "        flat_theta.extend(list(self.Bi_G.values()))\n",
    "        \n",
    "        self.alpha = np.random.rand(self.E)                     #individual offset parameters per exp\n",
    "        self.Bu = [dict() for i in range(self.E)]               #user bias per exp\n",
    "        self.Bi = [dict() for i in range(self.E)]               #item bias per exp\n",
    "        self.Gu = [dict() for i in range(self.E)]               #user latent factor vector repr per exp\n",
    "        self.Gi = [dict() for i in range(self.E)]               #item latent factor vector repr per exp\n",
    "        \n",
    "        flat_theta.extend(self.alpha)\n",
    "        for e in range(self.E):\n",
    "            for i in range(len(self.user_map)):\n",
    "                self.Bu[e][self.user_map[i]] = np.random.random(1).item()\n",
    "                flat_theta.append(self.Bu[e][self.user_map[i]]) \n",
    "        for e in range(self.E):        \n",
    "            for j in range(len(self.item_map)):\n",
    "                self.Bi[e][self.item_map[j]] = np.random.random(1).item() \n",
    "                flat_theta.append(self.Bi[e][self.item_map[j]])\n",
    "        for e in range(self.E):\n",
    "            for i in range(len(self.user_map)):\n",
    "                self.Gu[e][self.user_map[i]] = np.random.uniform(0,1,(1,self.k))\n",
    "                flat_theta.extend(np.array(list(self.Gu[e][self.user_map[i]])).flatten())\n",
    "        for e in range(self.E):        \n",
    "            for j in range(len(self.item_map)):\n",
    "                self.Gi[e][self.item_map[j]] = np.random.uniform(0,1,(1,self.k))\n",
    "                flat_theta.extend(np.array(list(self.Gi[e][self.item_map[j]])).flatten())\n",
    "        \n",
    "        self.recparam = (1 + len(self.user_set) + len(self.item_set) \\\n",
    "                            + self.k*(len(self.user_set) + len(self.item_set))) #per experience level parameters\n",
    "        self.globalparam = 1 + len(self.user_set) + len(self.item_set)   #global parameters\n",
    "        self.totalparams = self.recparam * self.E + self.globalparam\n",
    "        return np.array(flat_theta)\n",
    "    \n",
    "    def init_exp(self):\n",
    "        ''' Initializes experience for each user-item combination uniformly over rating time'''\n",
    "        self.eui = dict()  #experience dictionary of dictionaries (1: user level, 2: item level)\n",
    "        if self.mode == 1 or self.mode==2: # Community \n",
    "            num_items_in_level = round(len(self.train_data)/self.E)\n",
    "            if num_items_in_level ==0:\n",
    "                print(\"Something went wrong\")\n",
    "            else:\n",
    "                cur_level =0\n",
    "                for i in range(len(self.train_data)):\n",
    "                    review = self.train_data[i] \n",
    "                    user = review[\"review/userId\"]\n",
    "                    item = review[\"product/productId\"]\n",
    "                    if user not in self.eui:\n",
    "                        self.eui[user]= {}\n",
    "                    if i!=0 and i% num_items_in_level == 0 and cur_level != self.E-1:\n",
    "                        cur_level +=1\n",
    "                    self.eui[user][item] = cur_level\n",
    "        else:                        #user level    \n",
    "            for user in self.user_set:\n",
    "                self.eui[user] = {}\n",
    "                num_items_in_level = round(len(self.Iu[user])/self.E)\n",
    "                if num_items_in_level ==0:\n",
    "                    print(\"Something went wrong.\", len(self.Iu[user]),user)\n",
    "                cur_level = 0\n",
    "                for i in range(len(self.Iu[user])):\n",
    "                    if i!=0 and i% num_items_in_level == 0 and cur_level != self.E-1:\n",
    "                         cur_level+=1\n",
    "                    item = self.Iu[user][i]\n",
    "                    self.eui[user][item] = cur_level\n",
    "        print(\"Experience assignment done\")\n",
    "                \n",
    "    def OPT_rec(self,i,j,n,user):\n",
    "        '''\n",
    "         i = current experience level, j = jth rating of user, n = number of ratings given by user\n",
    "         internally modelled as experience 0 to E-1 (so experience E is invalid)\n",
    "        '''\n",
    "        if i==self.E or j==n:\n",
    "            return np.inf\n",
    "        elif self.OPT[i,j] >=0: #intial value = -1\n",
    "            return self.OPT[i,j]\n",
    "        else:\n",
    "            item = self.Iu[user][j]  # jth rating\n",
    "            rating = self.quickmap[user+\"-\"+item][\"review/score\"]\n",
    "            temp  = min(self.OPT_rec(i+1,j+1,n,user), self.OPT_rec(i,j+1,n,user))\n",
    "            rec_e = self.pred_e(user,item,i)   #current level rating\n",
    "            if temp == np.inf:\n",
    "                self.OPT[i,j] = (rec_e - rating)**2 \n",
    "            else:\n",
    "                self.OPT[i,j] = (rec_e - rating)**2 + temp\n",
    "                  \n",
    "            return self.OPT[i,j]\n",
    "    \n",
    "        \n",
    "    def assign_exp_level_iterative(self,user):\n",
    "        ''' Iterative solution for assigning experience to each user'''\n",
    "        n = len(self.Iu[user])\n",
    "        #compute the last column values i.e. the last item's values for each exp level\n",
    "        item = self.Iu[user][n-1]\n",
    "        for i in range(self.E):\n",
    "            rating = self.quickmap[user+\"-\"+item][\"review/score\"]\n",
    "            rec_e = self.pred_e(user,item,i)   #current level rating\n",
    "            self.OPT[i,n-1] = (rec_e - rating)**2\n",
    "        # now compute the upper most level row values (i.e. all items's highest exp level)\n",
    "        for j in range(n-2,-1,-1):\n",
    "            item = self.Iu[user][j]\n",
    "            rating = self.quickmap[user+\"-\"+item][\"review/score\"]\n",
    "            rec_e = self.pred_e(user,item,self.E-1)   #current level rating\n",
    "            self.OPT[self.E-1,j] = (rec_e - rating)**2 + self.OPT[self.E-1,j+1]\n",
    "        #now update every other value in the matrix\n",
    "        for j in range(n-2,-1,-1):\n",
    "            item = self.Iu[user][j]\n",
    "            for i in range(self.E-2,-1,-1):\n",
    "                rating = self.quickmap[user+\"-\"+item][\"review/score\"]\n",
    "                rec_e = self.pred_e(user,item,i)   #current level rating\n",
    "                temp  = min(self.OPT[i+1,j+1],self.OPT[i,j+1])\n",
    "                self.OPT[i,j] = (rec_e - rating)**2 + temp\n",
    "    \n",
    "    def assign_exp_level(self):\n",
    "        ''' Using the DP solution similar to Longest Common SubSequence, predict new experience level\n",
    "        for each user-item combination'''\n",
    "        k = 0\n",
    "        count=0\n",
    "        for user in self.Iu:\n",
    "            n = len(self.Iu[user])\n",
    "            self.OPT = np.matrix([[-1.0]*n]*self.E)  #initialize to invalid values\n",
    "            #recursive solution\n",
    "            #for i in range(self.E):\n",
    "            #    self.OPT_rec(i,0,n,user)\n",
    "            #Iterative solution:\n",
    "            self.assign_exp_level_iterative(user)\n",
    "            cur_level = np.argmin(self.OPT[:,0])\n",
    "            j = 0\n",
    "            item = self.Iu[user][j]\n",
    "            self.eui[user][item] = cur_level\n",
    "            start_level = cur_level\n",
    "            j+=1\n",
    "            while (j < n):\n",
    "                try: \n",
    "                    if cur_level != self.E-1 and self.OPT[cur_level,j] >= self.OPT[cur_level+1,j]:\n",
    "                        cur_level +=1\n",
    "                    item = self.Iu[user][j]\n",
    "                    if cur_level != self.eui[user][item]:\n",
    "                        count+=1\n",
    "                    self.eui[user][item] = cur_level\n",
    "                    j+=1\n",
    "                except Exception as e:\n",
    "                    print(e.args,i,j,n)\n",
    "            if k%1000==0:\n",
    "                print(\"user: {} start level: {} end level: {}\".format(user,start_level,cur_level))\n",
    "            k+=1 \n",
    "        print(\"Number of experience levels changed:{}\".format(count))\n",
    "        return count\n",
    "    \n",
    "    \n",
    "    def assign_exp_community(self):\n",
    "        print(\"Changing community experience levels\")\n",
    "        n = self.Ntrain\n",
    "        self.OPT = np.matrix([[-1.0]*n]*self.E)\n",
    "        count = 0 \n",
    "        #first get the last column values (i.e. the last review of the community)\n",
    "        review = self.train_data[-1]\n",
    "        user = review[\"review/userId\"]\n",
    "        item = review[\"product/productId\"]\n",
    "        rating = review[\"review/score\"]\n",
    "        for i in range(self.E):\n",
    "            rec_e = self.pred_e(user,item,i)   #current level rating\n",
    "            self.OPT[i,n-1] = (rec_e - rating)**2\n",
    "        # now compute the upper most level row values (i.e. all items's highest exp level)\n",
    "        for j in range(n-2,-1,-1):\n",
    "            review = self.train_data[j]\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            rating = review[\"review/score\"]\n",
    "            rec_e = self.pred_e(user,item,self.E-1)   #current level rating\n",
    "            self.OPT[self.E-1,j] = (rec_e - rating)**2 + self.OPT[self.E-1,j+1]\n",
    "        #now update every other value in the matrix\n",
    "        for j in range(n-2,-1,-1):\n",
    "            review = self.train_data[j]\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            for i in range(self.E-2,-1,-1):\n",
    "                rating = review[\"review/score\"]\n",
    "                rec_e = self.pred_e(user,item,i)   #current level rating\n",
    "                temp  = min(self.OPT[i+1,j+1],self.OPT[i,j+1])\n",
    "                self.OPT[i,j] = (rec_e - rating)**2 + temp\n",
    "        \n",
    "        cur_level = np.argmin(self.OPT[:,0])\n",
    "        j = 0\n",
    "        review = self.train_data[j]\n",
    "        user = review[\"review/userId\"]\n",
    "        item = review[\"product/productId\"]\n",
    "        self.eui[user][item] = cur_level\n",
    "        start_level = cur_level\n",
    "        j+=1\n",
    "        while (j < n):\n",
    "            try: \n",
    "                if cur_level != self.E-1 and self.OPT[cur_level,j] >= self.OPT[cur_level+1,j]:\n",
    "                        cur_level +=1\n",
    "                review = self.train_data[j]\n",
    "                user = review[\"review/userId\"]\n",
    "                item = review[\"product/productId\"]\n",
    "                if cur_level != self.eui[user][item]:\n",
    "                    count+=1\n",
    "                self.eui[user][item] = cur_level\n",
    "                j+=1\n",
    "            except Exception as e:\n",
    "                print(e.args,i,j,n)\n",
    "            if j%100000 ==0:\n",
    "                print(user,item, self.eui[user][item])\n",
    "        return count\n",
    "    \n",
    "    def retrieve_theta_components(self,theta):\n",
    "        ''' Sets all parameters from the long theta vector obtained after update rule'''\n",
    "        j = 0\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        self.alpha_G = theta[j]\n",
    "        j+=1\n",
    "        for i in range(umap_len):\n",
    "            self.Bu_G[self.user_map[i]] = theta[j]\n",
    "            j+=1\n",
    "        for i in range(imap_len):\n",
    "            self.Bi_G[self.item_map[i]] = theta[j]\n",
    "            j+=1 \n",
    "        for e in range(self.E):\n",
    "            self.alpha[e] = theta[j]\n",
    "            j+=1   \n",
    "        for e in range(self.E):\n",
    "            for i in range(umap_len):\n",
    "                self.Bu[e][self.user_map[i]] = theta[j]\n",
    "                j+=1\n",
    "        for e in range(self.E):\n",
    "            for i in range(imap_len):\n",
    "                self.Bi[e][self.item_map[i]] = theta[j]\n",
    "                j+=1 \n",
    "        for e in range(self.E):\n",
    "            for i in range(umap_len):\n",
    "                self.Gu[e][self.user_map[i]] = np.array(theta[j:j+self.k])\n",
    "                j+=self.k  \n",
    "        for e in range(self.E):\n",
    "            for i in range(imap_len):\n",
    "                self.Gi[e][self.item_map[i]] = np.array(theta[j:j+self.k])\n",
    "                j+=self.k   \n",
    "        if j!= len(theta):\n",
    "            print(\"Something went wrong. Not all theta values were used\")\n",
    "            \n",
    "    \n",
    "    def pred_e(self,user,item,e):\n",
    "        return self.alpha_G + self.Bu_G[user] + self.Bi_G[item] +\\\n",
    "                      self.alpha[e] + self.Bu[e][user] + self.Bi[e][item] +\\\n",
    "                      np.asscalar(np.dot(self.Gu[e][user], self.Gi[e][item].T))\n",
    "    \n",
    "    def f(self,theta):\n",
    "        '''Calculates the value of the objective function (loss) on the training data. '''\n",
    "        self.retrieve_theta_components(theta)\n",
    "        #mean squared error\n",
    "        error = 0\n",
    "        for review in self.train_data:\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            error += (self.pred_e(user,item,e) - review[\"review/score\"])**2\n",
    "        error /= self.Ntrain\n",
    "        #regularization terms\n",
    "        reg_complexity = 0\n",
    "        #ignore global values for now in regularization\n",
    "        Bu_np = np.array(list(self.Bu_G.values()))\n",
    "        Bi_np = np.array(list(self.Bi_G.values()))\n",
    "        reg_complexity = np.sum(np.square(Bu_np)) + np.sum(np.square(Bi_np))\n",
    "        for e in range(self.E):\n",
    "            reg_complexity += np.square(self.alpha[e])\n",
    "            Bu_np = np.array(list(self.Bu[e].values()))\n",
    "            Bi_np = np.array(list(self.Bi[e].values()))\n",
    "            reg_complexity += np.sum(np.square(Bu_np)) + np.sum(np.square(Bi_np))\n",
    "            for user in self.Gu[e]:\n",
    "                reg_complexity += np.linalg.norm(self.Gu[e][user])**2\n",
    "            for item in self.Gi[e]:\n",
    "                reg_complexity += np.linalg.norm(self.Gi[e][item])**2\n",
    "        #regularization (smoothing cost)\n",
    "        reg_term = 0\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        for e in range(1,self.E):\n",
    "            reg_term += (self.alpha[e-1] - self.alpha[e])**2\n",
    "        for e in range(1,self.E):\n",
    "            for i in range(umap_len):\n",
    "                reg_term += (self.Bu[e-1][self.user_map[i]] - self.Bu[e][self.user_map[i]])**2\n",
    "        for e in range(1,self.E):\n",
    "            for i in range(imap_len):\n",
    "                reg_term += (self.Bi[e-1][self.item_map[i]] - self.Bi[e][self.item_map[i]])**2       \n",
    "        for e in range(1,self.E):\n",
    "            for i in range(umap_len):\n",
    "                reg_term += np.linalg.norm(self.Gu[e-1][self.user_map[i]] - self.Gu[e][self.user_map[i]])**2  \n",
    "        for e in range(1,self.E):\n",
    "            for i in range(imap_len):\n",
    "                reg_term += np.linalg.norm(self.Gi[e-1][self.item_map[i]] - self.Gi[e][self.item_map[i]])**2\n",
    "        return (error + self.Lambda1* reg_complexity +  self.Lambda2 * reg_term)*0.5\n",
    "    \n",
    "    def fprime_one_func(self,theta):\n",
    "        ''' does all gradient work in one function. Should be definitely faster'''\n",
    "        self.retrieve_theta_components(theta)\n",
    "        flat_gradient = []\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        \n",
    "        self.alpha_G_grad = 0                              \n",
    "        self.Bu_G_grad = dict()                                      \n",
    "        self.Bi_G_grad = dict()                                     \n",
    "        \n",
    "        for i in range(len(self.user_map)):\n",
    "            self.Bu_G_grad[self.user_map[i]] = 0.0\n",
    "        for i in range(len(self.item_map)):\n",
    "            self.Bi_G_grad[self.item_map[i]] = 0.0\n",
    "        \n",
    "        self.alpha_grad = np.zeros(self.E)                     #individual offset parameters per exp\n",
    "        self.Bu_grad = [dict() for i in range(self.E)]               #user bias per exp\n",
    "        self.Bi_grad = [dict() for i in range(self.E)]               #item bias per exp\n",
    "        self.Gu_grad = [dict() for i in range(self.E)]               #user latent factor vector repr per exp\n",
    "        self.Gi_grad = [dict() for i in range(self.E)]               #item latent factor vector repr per exp\n",
    "        \n",
    "        for e in range(self.E):\n",
    "            for i in range(len(self.user_map)):\n",
    "                self.Bu_grad[e][self.user_map[i]] = 0.0\n",
    "                self.Gu_grad[e][self.user_map[i]] = np.zeros((1,self.k))\n",
    "            for j in range(len(self.item_map)):\n",
    "                self.Bi_grad[e][self.item_map[j]] = 0.0\n",
    "                self.Gi_grad[e][self.item_map[j]] = np.zeros((1,self.k))\n",
    "        \n",
    "        for review in self.train_data:\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            rat_diff = self.pred_e(user,item,e)- review[\"review/score\"] \n",
    "            rat_diff/= self.Ntrain\n",
    "            self.alpha_G_grad += rat_diff\n",
    "            self.Bu_G_grad[user] += rat_diff\n",
    "            self.Bi_G_grad[item] += rat_diff\n",
    "            self.alpha_grad[e] += rat_diff\n",
    "            self.Bu_grad[e][user] += rat_diff\n",
    "            self.Bi_grad[e][item] += rat_diff\n",
    "            self.Gu_grad[e][user] += rat_diff * self.Gi[e][item]\n",
    "            self.Gi_grad[e][item] += rat_diff * self.Gu[e][user]\n",
    "        \n",
    "        for i in range(len(self.user_map)):\n",
    "            user = self.user_map[i]\n",
    "            self.Bu_G_grad[user] += self.Lambda1 * self.Bu_G[user]\n",
    "        for j in range(len(self.item_map)):\n",
    "            item = self.item_map[j]\n",
    "            self.Bi_G_grad[item] += self.Lambda1 * self.Bi_G[item]\n",
    "        \n",
    "        for e in range(self.E):\n",
    "            self.alpha_grad[e] += self.Lambda1*self.alpha[e]\n",
    "            if e == self.E-1:\n",
    "                self.alpha_grad[e]  += self.Lambda2 * (self.alpha[e] - self.alpha[e-1])\n",
    "            elif e == 0:\n",
    "                self.alpha_grad[e]  += self.Lambda2 * (self.alpha[e] - self.alpha[e+1])\n",
    "            else:\n",
    "                self.alpha_grad[e]  += self.Lambda2 * (2*self.alpha[e] - self.alpha[e-1]  - self.alpha[e+1])\n",
    "            \n",
    "            for i in range(len(self.user_map)):\n",
    "                user = self.user_map[i]\n",
    "                self.Bu_grad[e][user] += self.Lambda1*self.Bu[e][user]\n",
    "                self.Gu_grad[e][user] += self.Lambda1*self.Gu[e][user]\n",
    "                if e == self.E-1:\n",
    "                    self.Bu_grad[e][user] += self.Lambda2* (self.Bu[e][user] - self.Bu[e-1][user])\n",
    "                    self.Gu_grad[e][user] += self.Lambda2* (self.Gu[e][user] - self.Gu[e-1][user]) \n",
    "                elif e==0:\n",
    "                    self.Bu_grad[e][user] += self.Lambda2* (self.Bu[e][user] - self.Bu[e+1][user])\n",
    "                    self.Gu_grad[e][user] += self.Lambda2* (self.Gu[e][user] - self.Gu[e+1][user]) \n",
    "                else:\n",
    "                    self.Bu_grad[e][user] += self.Lambda2* (2*self.Bu[e][user] - self.Bu[e-1][user] \\\n",
    "                                                            - self.Bu[e+1][user])\n",
    "                    self.Gu_grad[e][user] += self.Lambda2* (2*self.Gu[e][user] - self.Gu[e-1][user] \\\n",
    "                                                            - self.Gu[e+1][user])\n",
    "        \n",
    "            for j in range(len(self.item_map)):\n",
    "                item = self.item_map[j]\n",
    "                self.Bi_grad[e][item] += self.Lambda1*self.Bi[e][item]\n",
    "                self.Gi_grad[e][item] += self.Lambda1*self.Gi[e][item]\n",
    "                if e == self.E-1:\n",
    "                    self.Bi_grad[e][item] += self.Lambda2* (self.Bi[e][item] - self.Bi[e-1][item])\n",
    "                    self.Gi_grad[e][item] += self.Lambda2* (self.Gi[e][item] - self.Gi[e-1][item]) \n",
    "                elif e==0:\n",
    "                    self.Bi_grad[e][item] += self.Lambda2* (self.Bi[e][item] - self.Bi[e+1][item])\n",
    "                    self.Gi_grad[e][item] += self.Lambda2* (self.Gi[e][item] - self.Gi[e+1][item]) \n",
    "                else:\n",
    "                    self.Bi_grad[e][item] += self.Lambda2* (2*self.Bi[e][item] - self.Bi[e-1][item] \\\n",
    "                                                            - self.Bi[e+1][item])\n",
    "                    self.Gi_grad[e][item] += self.Lambda2* (2*self.Gi[e][item] - self.Gi[e-1][item] \\\n",
    "                                                            - self.Gi[e+1][item])\n",
    "        \n",
    "        #compute gradient wrt global parameters\n",
    "        flat_gradient.append(self.alpha_G_grad)\n",
    "        flat_gradient.extend(list(self.Bu_G_grad.values()))\n",
    "        flat_gradient.extend(list(self.Bi_G_grad.values()))\n",
    "        #compute gradient wrt experience parameters\n",
    "        flat_gradient.extend(self.alpha_grad)\n",
    "        for e in range(self.E): \n",
    "            flat_gradient.extend(list(self.Bu_grad[e].values()))\n",
    "        for e in range(self.E):\n",
    "            flat_gradient.extend(list(self.Bi_grad[e].values()))\n",
    "        for e in range(self.E):\n",
    "            flat_gradient.extend(np.array(list(self.Gu_grad[e].values())).flatten())\n",
    "        for e in range(self.E):\n",
    "            flat_gradient.extend(np.array(list(self.Gi_grad[e].values())).flatten())\n",
    "        return np.array(flat_gradient)\n",
    "    \n",
    "    def call(self,theta):\n",
    "        print(\"{} Objective value: {}\".format(self.i, self.f(theta)))\n",
    "        self.i+=1\n",
    "    \n",
    "    def objectiveloss_lbfgs(self,thetaguess, grad_tolerance):\n",
    "        self.i =0;\n",
    "        flat_theta_guess = thetaguess\n",
    "        flat_theta,value,d = opt.fmin_l_bfgs_b(self.f,flat_theta_guess,self.fprime_one_func,\\\n",
    "                                              disp=True,\\\n",
    "                                              maxiter = 30, callback = self.call, iprint=0)\n",
    "        #set the final parameters to the final value returned by fmin_l_bfgs_b\n",
    "        return flat_theta\n",
    "    \n",
    "    \n",
    "    def push_model(self):\n",
    "        ''' push the model towards more regularized place'''\n",
    "        e_alpha_avg = np.mean(self.alpha)\n",
    "        self.alpha_G += e_alpha_avg\n",
    "        self.alpha -= e_alpha_avg\n",
    "        \n",
    "        for user in self.Bu_G:\n",
    "            e_Bu_avg = 0 \n",
    "            for e in range(self.E):\n",
    "                e_Bu_avg += self.Bu[e][user]\n",
    "            e_Bu_avg /= self.E\n",
    "            self.Bu_G[user] += e_Bu_avg\n",
    "            for e in range(self.E):\n",
    "                self.Bu[e][user] -= e_Bu_avg\n",
    "        for item in self.Bi_G:\n",
    "            e_Bi_avg = 0\n",
    "            for e in range(self.E):\n",
    "                e_Bi_avg += self.Bi[e][item]\n",
    "            e_Bi_avg /= self.E\n",
    "            self.Bi_G[item] += e_Bi_avg\n",
    "            for e in range(self.E):\n",
    "                self.Bi[e][item] -= e_Bi_avg\n",
    "    \n",
    "    def als (self,grad_tolerance):\n",
    "        ''' bad name. not exactly ALS, but performs LBFGS gradient descent, and sets experience level'''\n",
    "        guess = self.final_param\n",
    "        for m in range(10):\n",
    "            print(\"Iteration {}:\".format(m+1))\n",
    "            print(\"Objective function value: {}\".format(self.f(guess)))\n",
    "            guess = self.objectiveloss_lbfgs(guess, grad_tolerance)\n",
    "            self.final_param = guess.copy()\n",
    "            self.retrieve_theta_components(guess)\n",
    "            print(\"Model alpha parameters(before push): \",[a + self.alpha_G for a in self.alpha])\n",
    "            self.push_model()\n",
    "            print(\"Model alpha parameters: \",[a + self.alpha_G for a in self.alpha])\n",
    "            if self.mode ==2:  #community learned\n",
    "                count = self.assign_exp_community()\n",
    "            elif self.mode==4: #user learned\n",
    "                count = self.assign_exp_level()\n",
    "            print(\"Objective function value: {}\".format(self.f(guess)))\n",
    "            if count==0:\n",
    "                print(\"Breaking\")\n",
    "                return\n",
    "            \n",
    "    def mse_test(self,test_data):\n",
    "        ''' Uses Mean Squared Error as evaluation metric on test data provided by user'''\n",
    "        self.retrieve_theta_components(self.final_param)\n",
    "        error = 0\n",
    "        unknown_data_count =0;\n",
    "        for review in test_data:\n",
    "            user = review[\"review/userId\"]\n",
    "            item = review[\"product/productId\"]\n",
    "            #assign nearest experience to user-item combo\n",
    "            rtime = int(review[\"review/time\"])\n",
    "            time_arr = []\n",
    "            for it in self.Iu[user]:\n",
    "                time_arr.append(int(self.quickmap[user+\"-\"+it][\"review/time\"]))\n",
    "            if all(time_arr[i] <= time_arr[i+1] for i in range(len(time_arr)-1))==False:\n",
    "                print(\"raising error. Something went wrong. List should be sorted by default\")\n",
    "            index = np.searchsorted(time_arr,rtime)\n",
    "            if index == len(self.Iu[user]):\n",
    "                closest_it = self.Iu[user][index-1]\n",
    "            else:\n",
    "                closest_it = self.Iu[user][index]\n",
    "            \n",
    "            e = self.eui[user][closest_it]\n",
    "            try:\n",
    "                error += (self.pred_e(user,item,e) - review[\"review/score\"])**2\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                unknown_data_count+=1\n",
    "        \n",
    "        if unknown_data_count>0:\n",
    "            print(\"Warning! Unknown {} new data rows; Incorporating this into MSE\".format(unknown_data_count))\n",
    "        return error / (len(test_data) - unknown_data_count)\n",
    "    \n",
    "    def fprime(self, theta):\n",
    "        ''' Calculates the gradient of objective function f()'''\n",
    "        self.retrieve_theta_components(theta)\n",
    "        flat_gradient = []\n",
    "        umap_len = len(self.user_map)\n",
    "        imap_len = len(self.item_map)\n",
    "        #compute gradient wrt global parameters\n",
    "        flat_gradient.append(self.compute_gradient_wrt_alpha_global())\n",
    "        Bu_grad = self.compute_gradient_wrt_Bu_global()\n",
    "        Bi_grad = self.compute_gradient_wrt_Bi_global()\n",
    "        flat_gradient.extend(list(Bu_grad.values()))\n",
    "        flat_gradient.extend(list(Bi_grad.values()))\n",
    "        #compute gradient wrt experience parameters\n",
    "        for e in range(self.E):\n",
    "            flat_gradient.append(self.compute_gradient_wrt_alpha(e))\n",
    "        for e in range(self.E): \n",
    "            Bu_grad = self.compute_gradient_wrt_Bu(e)\n",
    "            flat_gradient.extend(list(Bu_grad.values()))\n",
    "        for e in range(self.E):\n",
    "            Bi_grad = self.compute_gradient_wrt_Bi(e)\n",
    "            flat_gradient.extend(list(Bi_grad.values()))\n",
    "        for e in range(self.E):\n",
    "            Gu_grad = self.compute_gradient_wrt_Gu(e)\n",
    "            flat_gradient.extend(np.array(list(Gu_grad.values())).flatten())\n",
    "        for e in range(self.E):\n",
    "            Gi_grad = self.compute_gradient_wrt_Gi(e)\n",
    "            flat_gradient.extend(np.array(list(Gi_grad.values())).flatten())\n",
    "        return np.array(flat_gradient)\n",
    "    \n",
    "    def vanilla_gd(self,eta,guess):\n",
    "        self.i =0;\n",
    "        flat_theta_guess = guess\n",
    "        for i in range(100):\n",
    "            flat_gradient = self.fprime(flat_theta_guess)\n",
    "            flat_theta_guess -= eta*flat_gradient\n",
    "            if i%50 ==0: print(\"{} U : Objective value: {}\".format(i,self.f(flat_theta_guess)))\n",
    "            self.i +=1\n",
    "        return flat_theta_guess\n",
    "    \n",
    "    def vanilla_als (self,eta):\n",
    "        guess = self.init_theta()\n",
    "        #print(\"param = \",guess[self.recparam])\n",
    "        for m in range(100):\n",
    "            guess = self.vanilla_gd(eta, guess)\n",
    "            self.final_param = guess\n",
    "            self.retrieve_theta_components(guess)\n",
    "            count = self.assign_exp_level()\n",
    "            if count==0:\n",
    "                print(\"Breaking\")\n",
    "                return\n",
    "   \n",
    "    def compute_gradient_wrt_alpha_global(self):\n",
    "        tempsum = 0\n",
    "        for review in self.train_data:  #each user item id combo\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            tempsum += ( self.pred_e(user,item,e)- review[\"review/score\"])\n",
    "        tempsum /= self.Ntrain\n",
    "        return tempsum\n",
    "        \n",
    "    def compute_gradient_wrt_Bu_global(self):\n",
    "        Bu_grad = {}\n",
    "        for user in self.Bu_G: \n",
    "            total = 0.0\n",
    "            for item in self.Iu[user]:\n",
    "                e = self.eui[user][item]\n",
    "                total += ( self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Bu_G[user]\n",
    "            Bu_grad[user] = total\n",
    "        return Bu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Bi_global(self):\n",
    "        Bi_grad = {}\n",
    "        for item in self.Bi_G:\n",
    "            total = 0.0\n",
    "            for user in self.Ui[item]:\n",
    "                e = self.eui[user][item]\n",
    "                total += ( self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Bi_G[item]\n",
    "            Bi_grad[item] = total\n",
    "        return Bi_grad\n",
    "    \n",
    "    def compute_gradient_wrt_alpha(self,exp):\n",
    "        ''' Compute gradient of objective with respect to alpha parameter of given experience exp level'''\n",
    "        tempsum = 0\n",
    "        for review in self.train_data:  #each user item id combo\n",
    "            user = review['review/userId']\n",
    "            item = review[\"product/productId\"]\n",
    "            e = self.eui[user][item]\n",
    "            if e == exp:  #only take the values pertaining the current level\n",
    "                tempsum += ( self.pred_e(user,item,e) - review[\"review/score\"]) \n",
    "        \n",
    "        tempsum /= self.Ntrain\n",
    "        \n",
    "        #regularization term\n",
    "        tempsum += self.Lambda1*self.alpha[exp]\n",
    "        \n",
    "        if exp == self.E-1:\n",
    "            tempsum += self.Lambda2 * (self.alpha[exp] - self.alpha[exp-1])\n",
    "        elif exp == 0:\n",
    "            tempsum += self.Lambda2 * (self.alpha[exp] - self.alpha[exp+1])\n",
    "        else:\n",
    "            tempsum += self.Lambda2 * (2*self.alpha[exp] - self.alpha[exp-1]  - self.alpha[exp+1])\n",
    "        return tempsum\n",
    "    \n",
    "    def compute_gradient_wrt_Bu(self,e):\n",
    "        ''' Compute gradient of objective with respect to Bu parameter'''\n",
    "        Bu_grad = {}\n",
    "        for user in self.Bu[e]: \n",
    "            total = 0.0\n",
    "            for item in self.Iu[user]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total += ( self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Bu[e][user]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Bu[e][user] - self.Bu[e-1][user])\n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Bu[e][user] - self.Bu[e+1][user])\n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Bu[e][user] - self.Bu[e-1][user]  - self.Bu[e+1][user])\n",
    "            Bu_grad[user] = total\n",
    "        return Bu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Bi(self,e):\n",
    "        ''' Compute gradient of objective with respect to Bi parameter'''\n",
    "        Bi_grad = {}\n",
    "        for item in self.Bi[e]:\n",
    "            total = 0.0\n",
    "            for user in self.Ui[item]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total +=  (self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]) \n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Bi[e][item]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Bi[e][item] - self.Bi[e-1][item])\n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Bi[e][item] - self.Bi[e+1][item])\n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Bi[e][item] - self.Bi[e-1][item]  - self.Bi[e+1][item])\n",
    "            Bi_grad[item] = total\n",
    "        return Bi_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Gu(self,e):\n",
    "        ''' Compute gradient of objective with respect to Gu parameter'''\n",
    "        Gu_grad  = {} \n",
    "        for user in self.Gu[e]:   \n",
    "            total = np.zeros((1,self.k)) \n",
    "            for item in self.Iu[user]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total+= np.multiply((self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]),\\\n",
    "                    self.Gi[e][item])\n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Gu[e][user]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Gu[e][user] - self.Gu[e-1][user]) \n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Gu[e][user] - self.Gu[e+1][user]) \n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Gu[e][user] - self.Gu[e-1][user]  - self.Gu[e+1][user])\n",
    "            Gu_grad[user] = total.copy()\n",
    "        return Gu_grad\n",
    "    \n",
    "    def compute_gradient_wrt_Gi(self,e):\n",
    "        ''' Compute gradient of objective with respect to Gi parameter'''\n",
    "        Gi_grad = {}\n",
    "        for item in self.Gi[e]:\n",
    "            total = np.zeros((1,self.k))\n",
    "            for user in self.Ui[item]:\n",
    "                if self.eui[user][item] == e:\n",
    "                    total+= np.multiply((self.pred_e(user,item,e) - self.quickmap[user+'-'+item][\"review/score\"]),\\\n",
    "                                        self.Gu[e][user])\n",
    "            total /= self.Ntrain\n",
    "            total += self.Lambda1*self.Gi[e][item]\n",
    "            if e == self.E-1:\n",
    "                total += self.Lambda2* (self.Gi[e][item] - self.Gi[e-1][item])\n",
    "            elif e==0:\n",
    "                total += self.Lambda2* (self.Gi[e][item] - self.Gi[e][item]) \n",
    "            else:\n",
    "                total += self.Lambda2* (2*self.Gi[e][item] - self.Gi[e-1][item]  - self.Gi[e+1][item])\n",
    "            Gi_grad[item] = total.copy()\n",
    "        return Gi_grad\n",
    "    \n",
    "        \n",
    "    def deepish_copy(self,org):\n",
    "        '''much, much faster than deepcopy, for a dict of the simple python types.'''\n",
    "        out = dict().fromkeys(org)\n",
    "        for k,v in org.items():\n",
    "            try:\n",
    "                out[k] = v.copy()   # dicts, sets\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    out[k] = v[:]   # lists, tuples, strings, unicode\n",
    "                except TypeError:\n",
    "                    out[k] = v      # ints\n",
    "\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience assignment done\n"
     ]
    }
   ],
   "source": [
    "lfmObj1 = ExpertiseLFM(train,Iu, Ui,quickmap,distinct_user_set,distinct_item_set,user_map_int, item_map_int,5,0.001,0.1,5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"ratebeer_user_expertise_lfm_results_random\", lfmObj1.final_param)\n",
    "#np.savetxt(\"beeradvocate_user_expertise_lfm_results_lastrating\", lfmObj1.final_param)\n",
    "#np.savetxt(\"beeradvocate_user_expertise_lfm_results_random\", lfmObj2.final_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eui_dict = {}\n",
    "for user in lfmObj1.eui:\n",
    "    for item in lfmObj1.eui[user]:\n",
    "        eui_dict[user+'<?>'+item] = int(lfmObj1.eui[user][item])\n",
    "\n",
    "with open(\"ratebeer_random_eui.json\",'w') as outfile:\n",
    "#with open(\"beeradvocate_lastrating_eui.json\",'w') as outfile:\n",
    "        json.dump(eui_dict,outfile)\n",
    "    #json.dump(lfmObj1.eui,outfile)\n",
    "#print(\"File {} written\".format(\"finefood_random_eui.json\"))\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
